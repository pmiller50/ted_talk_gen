{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8VMnuH-l2o_"
   },
   "source": [
    "TED talk text generator\n",
    "\n",
    "Generate using a character based model.\n",
    "\n",
    "The code is this notebook is a partial modification of several tutorials, blog posts and YouTube videos. The main sources include:\n",
    "* [Text Generation With LSTM Recurrent Neural Networks in Python with Keras](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/) by Dr. Jason Brownlee\n",
    "* [Text Generation with Python and TensorFlow/Keras](https://stackabuse.com/text-generation-with-python-and-tensorflow-keras/) by Dan Nelson\n",
    "* YouTube: [167 - Text prediction using LSTM (English text)](https://youtu.be/zyCpntcVKSo?t=2) by Sreenivas B.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1613538403438,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "OLpQP9ZPs3Z8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.train import latest_checkpoint\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "import random\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1613538403660,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "waLxIXEXmCoW",
    "outputId": "c9837e2d-5c4e-489f-9030-e6c18a9bcd1a"
   },
   "outputs": [],
   "source": [
    "# Attach to my Google drive so I can save the csv file later\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1613538403660,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "1ygYMqkOddlx"
   },
   "outputs": [],
   "source": [
    "#tag_name = 'all_transcripts'\n",
    "#tag_name = 'brain'\n",
    "#tag_name = 'business'\n",
    "#tag_name = 'creativity'\n",
    "#tag_name = 'culture'\n",
    "#tag_name = 'psychology'\n",
    "#tag_name = 'science'\n",
    "tag_name = 'all'\n",
    "\n",
    "lower_corpus = False\n",
    "\n",
    "if lower_corpus:\n",
    "    corpus_file_name = tag_name + '_lowercase'\n",
    "else:\n",
    "    corpus_file_name = tag_name + '_sentence_case'\n",
    "\n",
    "# This switch makes it easier running locally or in a Google Colab environment\n",
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    root_path = '/content/drive/MyDrive/ted/'\n",
    "    data_path = f'{root_path}'\n",
    "else:\n",
    "    root_path = '../'\n",
    "    data_path = f'{root_path}data/'\n",
    "    \n",
    "model_path = f'{root_path}models/'\n",
    "logs_path = f'{root_path}logs/'\n",
    "    \n",
    "sequence_length = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 863,
     "status": "ok",
     "timestamp": 1613538403661,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "V1ljkpt0l1kx"
   },
   "outputs": [],
   "source": [
    "with open(f'{data_path}{corpus_file_name}.txt', encoding='utf-8') as f:\n",
    "    corpus = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 1322,
     "status": "ok",
     "timestamp": 1613538404130,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "K8pyPFcnmCD9",
    "outputId": "3813cc1e-6871-4766-9709-f5e11b5f7660"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Good morning. How are you?  Good. It's been great, hasn't it? I've been blown away by the whole thing. In fact, I'm leaving.  There have been three themes running through the conference, which are relevant to what I want to talk about. One is the extraordinary evidence of human creativity in all of the presentations that we've had and in all of the people here; just the variety of it and the range of it. The second is that it's put us in a place where we have no idea what's going to happen in te\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDIMVXs-kwz3"
   },
   "source": [
    "The code below is used in almost every article I have seen about LSTM for text generation, but this snippet is adapted from :\n",
    "https://www.kaggle.com/mrisdal/intro-to-lstms-w-keras-gpu-for-text-generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '$', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'è', 'é', '–', '’', '“', '”', '…', '♫']\n"
     ]
    }
   ],
   "source": [
    "all_chars = sorted(list(set(corpus)))\n",
    "\n",
    "#remove most punctuation, but leave spaces, exclamation points, and periods\n",
    "list_to_remove = ['\"', '&', '-', ',', \"'\", '/', ';',  '—', '%','[', ']' ]\n",
    "\n",
    "chars = [character for character in all_chars if character not in list_to_remove]\n",
    "print(chars)\n",
    "# hat tip to this post for the idea of removing one list from another\n",
    "# https://www.geeksforgeeks.org/python-remove-all-values-from-a-list-present-in-other-list/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all unwanted characters from the original corpus\n",
    "corpus_list = [character for character in corpus if character not in list_to_remove]\n",
    "\n",
    "# Re-join all letters back into a single string as the updated corpus\n",
    "corpus = ''.join(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1313,
     "status": "ok",
     "timestamp": 1613538404131,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "KW8k2n7piPca",
    "outputId": "70c7cd09-9650-4e03-8fb5-561532a8aeed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in the corpus: 75\n"
     ]
    }
   ],
   "source": [
    "# If running models with punctuation removed, leave commented out\n",
    "#chars = sorted(list(set(corpus)))\n",
    "\n",
    "print('Number of unique characters in the corpus:', len(chars))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1304,
     "status": "ok",
     "timestamp": 1613538404131,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "vwPryvRueRtT",
    "outputId": "a90beecb-f0fc-48ef-e803-c04afc88d5ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '$': 2, '.': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, '?': 14, 'A': 15, 'B': 16, 'C': 17, 'D': 18, 'E': 19, 'F': 20, 'G': 21, 'H': 22, 'I': 23, 'J': 24, 'K': 25, 'L': 26, 'M': 27, 'N': 28, 'O': 29, 'P': 30, 'Q': 31, 'R': 32, 'S': 33, 'T': 34, 'U': 35, 'V': 36, 'W': 37, 'X': 38, 'Y': 39, 'Z': 40, 'a': 41, 'b': 42, 'c': 43, 'd': 44, 'e': 45, 'f': 46, 'g': 47, 'h': 48, 'i': 49, 'j': 50, 'k': 51, 'l': 52, 'm': 53, 'n': 54, 'o': 55, 'p': 56, 'q': 57, 'r': 58, 's': 59, 't': 60, 'u': 61, 'v': 62, 'w': 63, 'x': 64, 'y': 65, 'z': 66, 'è': 67, 'é': 68, '–': 69, '’': 70, '“': 71, '”': 72, '…': 73, '♫': 74}\n"
     ]
    }
   ],
   "source": [
    "# Show character to index mapping\n",
    "print (char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1294,
     "status": "ok",
     "timestamp": 1613538404132,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "RqMa6shPiQrd",
    "outputId": "6965acf5-10cf-4624-efde-abb4f61eeb4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: '!', 2: '$', 3: '.', 4: '0', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: '?', 15: 'A', 16: 'B', 17: 'C', 18: 'D', 19: 'E', 20: 'F', 21: 'G', 22: 'H', 23: 'I', 24: 'J', 25: 'K', 26: 'L', 27: 'M', 28: 'N', 29: 'O', 30: 'P', 31: 'Q', 32: 'R', 33: 'S', 34: 'T', 35: 'U', 36: 'V', 37: 'W', 38: 'X', 39: 'Y', 40: 'Z', 41: 'a', 42: 'b', 43: 'c', 44: 'd', 45: 'e', 46: 'f', 47: 'g', 48: 'h', 49: 'i', 50: 'j', 51: 'k', 52: 'l', 53: 'm', 54: 'n', 55: 'o', 56: 'p', 57: 'q', 58: 'r', 59: 's', 60: 't', 61: 'u', 62: 'v', 63: 'w', 64: 'x', 65: 'y', 66: 'z', 67: 'è', 68: 'é', 69: '–', 70: '’', 71: '“', 72: '”', 73: '…', 74: '♫'}\n"
     ]
    }
   ],
   "source": [
    "# Show index to character mapping\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1286,
     "status": "ok",
     "timestamp": 1613538404132,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "ns5RcDesiQzZ",
    "outputId": "fc7676a5-4d17-4b11-e18c-929b51c72f50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input corpus contains 267,106 characters.\n"
     ]
    }
   ],
   "source": [
    "print (f'The input corpus contains {len(corpus):,} characters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 1278,
     "status": "ok",
     "timestamp": 1613538404132,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "85NHcjWuiQ7D"
   },
   "outputs": [],
   "source": [
    "#Save to csv to save computation time for streamlit web app\n",
    "pd.DataFrame.from_dict(indices_char, orient='index').to_csv('../web/indices_char.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to csv to save computation time for streamlit web app\n",
    "pd.DataFrame.from_dict(char_indices, orient='index').to_csv('../web/char_indices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXgbFM-46jrS"
   },
   "source": [
    "The model will use arbitrary length of characters, e.g. 40, and then predict the next character that will appear (the 41st).\n",
    "\n",
    "I would like to change this sequence length in different models, to see how it might affect the model's performance.\n",
    "\n",
    "Larger might be better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1613538404133,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "CgLONw9RiRC-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNWrhS2LJkOt"
   },
   "source": [
    "Loop through the corpus, creating segments of 40 characters, plus a segment of a single character that would appear after it. These segments are then converted into their respective digits, and loaded into X\n",
    "\n",
    "In addition, create a list of target values. The target, y, is a single text character, and is also converted into a corresponding numeric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1265,
     "status": "ok",
     "timestamp": 1613538404133,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "uPWsaG39Si52",
    "outputId": "ec027126-9d6e-4bb4-cd0d-965a7c65f1ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good morning. How are you?  Good. Its been great h'"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1613538404133,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "pB06ivEKOa2f",
    "outputId": "7f8f681f-b956-4c94-a8d1-fed28e011bd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ood morning. How are you?  Good. Its bee'"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1248,
     "status": "ok",
     "timestamp": 1613538404134,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "QN8H5lmRPzV8",
    "outputId": "ebd703f3-9fd8-4a71-f00a-791ff00b8ceb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 2091,
     "status": "ok",
     "timestamp": 1613538404984,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "z4bwf70jiRIF"
   },
   "outputs": [],
   "source": [
    "# For future modeling, we could try to offset the sequences by more than one\n",
    "# letter. For now the model will look at every sequence right after another.\n",
    "step = 1\n",
    "\n",
    "X_numeric_list = []\n",
    "y_numeric_list = []\n",
    "\n",
    "\n",
    "for i in range (0, len(corpus) - sequence_length, step):\n",
    "    # To find X when still as characters, loop through and extract\n",
    "    # a sequence for example, from the 2nd to the 42nd, as in corpus[1:41] since \n",
    "    # the string index is zero-based\n",
    "    X_char_sequence = corpus[i:i + sequence_length]  #exclusive\n",
    "    y_char = corpus[i + sequence_length]\n",
    "\n",
    "    # Convert the X character sequence into a list of integers, using the \n",
    "    # dictionary created above.\n",
    "    X_numeric_list.append( [char_indices[letter] for letter in X_char_sequence])\n",
    "    # Also convert target letter y to it's corresponding numeric value in the\n",
    "    # dictionary\n",
    "    y_numeric_list.append(char_indices[y_char])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2085,
     "status": "ok",
     "timestamp": 1613538404984,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "OAIoz7XIXIWV",
    "outputId": "1368effc-745f-4a2a-df82-09c0a57e1d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 55, 55, 44, 0, 53, 55, 58, 54, 49, 54, 47, 3, 0, 22, 55, 63, 0, 41, 58, 45, 0, 65, 55, 61, 14, 0, 0, 21, 55, 55, 44, 3, 0, 23, 60, 59, 0, 42, 45, 45, 54, 0, 47, 58, 45, 41, 60, 0, 48, 41, 59, 54, 60, 0, 49, 60, 14, 0, 23, 62, 45, 0, 42, 45, 45, 54, 0, 42, 52, 55, 63, 54, 0, 41, 63, 41, 65, 0, 42]\n",
      "[55, 55, 44, 0, 53, 55, 58, 54, 49, 54, 47, 3, 0, 22, 55, 63, 0, 41, 58, 45, 0, 65, 55, 61, 14, 0, 0, 21, 55, 55, 44, 3, 0, 23, 60, 59, 0, 42, 45, 45, 54, 0, 47, 58, 45, 41, 60, 0, 48, 41, 59, 54, 60, 0, 49, 60, 14, 0, 23, 62, 45, 0, 42, 45, 45, 54, 0, 42, 52, 55, 63, 54, 0, 41, 63, 41, 65, 0, 42, 65]\n"
     ]
    }
   ],
   "source": [
    "# Look at the first two converted sequences\n",
    "print ( X_numeric_list[0])\n",
    "print ( X_numeric_list[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_numeric_list).to_csv('../web/X_numeric.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2071,
     "status": "ok",
     "timestamp": 1613538404985,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "pUBI2jozXYT1",
    "outputId": "5b950e77-26a9-45a7-d5df-a218ee01509e"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(y_numeric_list).to_csv('../web/y_numeric.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2064,
     "status": "ok",
     "timestamp": 1613538404986,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "PhR81VtiXzyJ",
    "outputId": "ce15680c-aa72-4aee-9e48-230cfa3acddc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good morning. How are you?  Good. Its been '"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:43]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2X_QDPSqYAmR"
   },
   "source": [
    "This example is a little hard to follow, since we happened to be in the middle of the word 'been'. The letter e is mapped to 51.\n",
    "\n",
    "However the beginning of the sequence has been shifted by one as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2054,
     "status": "ok",
     "timestamp": 1613538404986,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "nkX8BKMMX4hh",
    "outputId": "7ff2f80c-cfd3-432f-b2ac-fbbf18042b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 267,026 entries in X_numeric_list\n"
     ]
    }
   ],
   "source": [
    "print (f'There are {len(X_numeric_list):,} entries in X_numeric_list') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tn3uKqnJasUf"
   },
   "source": [
    "An LSTM model needs the X data to be in 3 dimensions:\n",
    "* Samples (number of rows)\n",
    "* Time steps (this implies time series. In this example this corresponds to the sequence_length)\n",
    "* Features (the target, or y variable)\n",
    "\n",
    "This [blog post by Dr. John Brownlee](https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/) contains a longer explanation, which I paraphrased here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "executionInfo": {
     "elapsed": 2825,
     "status": "ok",
     "timestamp": 1613538405763,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "qH7OG0kAYALM"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "# Samples is the total number of 40 character text fragments created above\n",
    "# Time step is the sequence length, which is this case is 40, but might change\n",
    "# in other model variations\n",
    "# Feature is one, since the model is predicting one character at a time\n",
    "X = np.reshape(X_numeric_list, (len(X_numeric_list), sequence_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2819,
     "status": "ok",
     "timestamp": 1613538405763,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "WYTRXPhbarU0",
    "outputId": "3263bee5-a669-47b5-b02a-9f03e452b4cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267026, 80, 1)"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "executionInfo": {
     "elapsed": 2813,
     "status": "ok",
     "timestamp": 1613538405764,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "lrG9AduNY47g"
   },
   "outputs": [],
   "source": [
    "# normalize/scale the data by dividing by the length of the character list.\n",
    "X = X / len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2807,
     "status": "ok",
     "timestamp": 1613538405764,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "bhvp9pN5_txN",
    "outputId": "52fbf777-410c-4631-9f36-b7cf535fd51e"
   },
   "outputs": [],
   "source": [
    "# Look at the first value of X\n",
    "#X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cqa6ZNx4AQwE"
   },
   "source": [
    "Even thought the values for the target variable are integers, they are essentially labels for the predicted characters. They are one-hot encoded using the to_categorical function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2794,
     "status": "ok",
     "timestamp": 1613538405765,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "XqS9wPlW_t5F",
    "outputId": "79c00f03-9da9-4588-a73b-a36dad43f0b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y_numeric_list)\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lb1V-QYZFdoe"
   },
   "source": [
    "---\n",
    "### Load LSTM Model\n",
    "In this notebook, load a model that was previously trained and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "executionInfo": {
     "elapsed": 2785,
     "status": "ok",
     "timestamp": 1613538405765,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "R1tBdmEw_t-b"
   },
   "outputs": [],
   "source": [
    "# Save the model to my Google Drive so I can load it later from another notebook\n",
    "# model = load_model(f'/content/drive/MyDrive/ted/models/ted_model_{tag_name}')\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6235,
     "status": "ok",
     "timestamp": 1613538409235,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "3TuIcmh9W_16",
    "outputId": "fc764c9f-8eec-4e66-f5c5-9d9c9532645f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model:../models/all_50_75_80_seq\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 500)               1004000   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 75)                37575     \n",
      "=================================================================\n",
      "Total params: 1,041,575\n",
      "Trainable params: 1,041,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # define the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(1000, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(256))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "\n",
    "# # Load the previously saved weights\n",
    "# model.load_weights(latest)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam' , metrics = ['accuracy','Recall','Precision'])\n",
    "\n",
    "\n",
    "#Models are saved in this format:\n",
    "# model.save(f'{model_path}/{tag_name}_{input_nodes_count}_{layer_2_nodes_count}')\n",
    "print(f'Loading model:{model_path}{tag_name}_50_75_80_seq')\n",
    "model = load_model(f'{model_path}{tag_name}_500_75_80')\n",
    "\n",
    "# print(f'Loading model:{model_path}{tag_name}_40_256')\n",
    "# model = load_model(f'{model_path}{tag_name}_40_256')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yg18vLEitH-5"
   },
   "source": [
    "X_numeric_list contains all of our 40 character sequences. Choose one for a seed for the text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6228,
     "status": "ok",
     "timestamp": 1613538409236,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "3zTBAJRh_uC3",
    "outputId": "d6a0b853-b399-4b7c-e898-0166e55fb84f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random start index for seed text: 146483 sequence.\n",
      "[48, 49, 59, 0, 42, 55, 55, 51, 0, 26, 49, 45, 59, 56, 55, 60, 60, 49, 54, 47, 0, 54, 55, 0, 55, 54, 45, 0, 63, 41, 54, 60, 59, 0, 60, 55, 0, 53, 45, 45, 60, 0, 53, 45, 0, 49, 54, 0, 56, 45, 58, 59, 55, 54, 0, 41, 54, 65, 53, 55, 58, 45, 0, 54, 55, 0, 54, 55, 0, 54, 55, 0, 54, 55, 0, 54, 55, 3, 0, 34]\n"
     ]
    }
   ],
   "source": [
    "seed_start = random.randint(0, len(corpus) - sequence_length)\n",
    "print(f'Random start index for seed text: {seed_start} sequence.')\n",
    "\n",
    "X_seeded = X_numeric_list[seed_start]\n",
    "print(X_seeded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vj_Nlck8FRl"
   },
   "source": [
    "Convert this back to text so we can see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6220,
     "status": "ok",
     "timestamp": 1613538409236,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "lnHGnP3O_uFB",
    "outputId": "e087a11d-97d8-4e5b-efb3-bd0038c269a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'his book Liespotting no one wants to meet me in person anymore no no no no no. T'"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_string = ''.join([indices_char[letter_code] for letter_code in X_seeded])\n",
    "seed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6212,
     "status": "ok",
     "timestamp": 1613538409237,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "nmSHu7KtBULP",
    "outputId": "858e7171-be72-46b9-94a1-3d06586e19d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his book Liespotting no one wants to meet me in person anymore no no no no no. T\n",
      "is book Liespotting no one wants to meet me in person anymore no no no no no. Th\n",
      "s book Liespotting no one wants to meet me in person anymore no no no no no. The\n",
      " book Liespotting no one wants to meet me in person anymore no no no no no. They\n",
      "book Liespotting no one wants to meet me in person anymore no no no no no. They \n",
      "ook Liespotting no one wants to meet me in person anymore no no no no no. They s\n",
      "ok Liespotting no one wants to meet me in person anymore no no no no no. They sa\n",
      "k Liespotting no one wants to meet me in person anymore no no no no no. They say\n",
      " Liespotting no one wants to meet me in person anymore no no no no no. They say \n",
      "Liespotting no one wants to meet me in person anymore no no no no no. They say I\n",
      "iespotting no one wants to meet me in person anymore no no no no no. They say It\n",
      "espotting no one wants to meet me in person anymore no no no no no. They say Its\n",
      "spotting no one wants to meet me in person anymore no no no no no. They say Its \n",
      "potting no one wants to meet me in person anymore no no no no no. They say Its o\n",
      "otting no one wants to meet me in person anymore no no no no no. They say Its ok\n"
     ]
    }
   ],
   "source": [
    "# We can also use the seed_start value to see a larger picture of the original text\n",
    "for j in range(seed_start, seed_start + 15):\n",
    "    seed_numeric = X_numeric_list[j]\n",
    "    print (''.join([indices_char[letter_code] for letter_code in seed_numeric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6205,
     "status": "ok",
     "timestamp": 1613538409237,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "XP-zzHQIBUIa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvDwmnKi8KFC"
   },
   "source": [
    "To generate text, we need to change the input text into a 3D shape as we did the X input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6984,
     "status": "ok",
     "timestamp": 1613538410022,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "21d8U6qaAADc",
    "outputId": "da487977-5e85-4468-8be6-505eb1038510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A prediction's shape:(1, 75)\n",
      "Prediction:\n",
      "[[7.62266591e-02 1.56492236e-10 7.49858009e-10 1.60318259e-02\n",
      "  2.73117053e-07 2.83879245e-07 1.86448960e-06 1.35662344e-06\n",
      "  8.02136037e-06 7.71028681e-06 5.10848244e-04 1.34363449e-06\n",
      "  7.32487127e-11 1.14947204e-06 3.36395529e-11 3.70571379e-10\n",
      "  4.99591416e-13 1.01771785e-11 5.68774333e-11 2.73902554e-08\n",
      "  3.22840227e-11 2.09589412e-08 2.71267600e-12 1.09397511e-07\n",
      "  1.04868675e-11 4.04120425e-16 5.08398026e-19 7.02022399e-11\n",
      "  1.31574534e-13 8.80105655e-10 2.48859716e-13 1.91020651e-14\n",
      "  8.70046602e-13 4.33746178e-10 9.45029939e-08 7.68499500e-12\n",
      "  4.78442537e-16 8.30269176e-13 5.84251436e-15 5.64952443e-14\n",
      "  1.45062042e-16 3.29776853e-02 3.70638096e-03 1.77909285e-02\n",
      "  4.50406671e-02 1.18002005e-01 8.07497092e-03 4.96369693e-03\n",
      "  1.54471353e-01 3.97264697e-02 8.50018637e-07 1.48961935e-02\n",
      "  1.97547134e-02 4.17924523e-02 3.48653160e-02 1.53230965e-01\n",
      "  1.04755405e-02 2.48772845e-13 3.75947393e-02 3.18075679e-02\n",
      "  5.99242896e-02 2.02435795e-02 3.15156532e-03 2.00918335e-02\n",
      "  1.29642838e-03 3.33282910e-02 1.72944645e-08 1.67500406e-11\n",
      "  3.68865501e-14 1.34634765e-15 5.08815282e-11 5.35595534e-15\n",
      "  1.42238634e-20 1.05249239e-14 3.10559495e-11]]\n"
     ]
    }
   ],
   "source": [
    "temp_x = np.reshape(X_seeded, (1, len(X_seeded) , 1))\n",
    "# normalize/scale the data by dividing by the length of the character list.\n",
    "temp_x = temp_x / len(chars)\n",
    "prediction = model.predict(temp_x, verbose=0)\n",
    "print(f\"A prediction's shape:{prediction.shape}\")\n",
    "print('Prediction:')\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dQEpt5uAJcE"
   },
   "source": [
    "Each prediction produces an result of shape (1, 75), and contains a predicted probability of a character. Use argmax to find the index of the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6977,
     "status": "ok",
     "timestamp": 1613538410022,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "7XoGksJ2AIoZ",
    "outputId": "a4ac631e-f9bb-4017-e96f-ed8a8ff4cf1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ax7a5bKoA3FJ"
   },
   "source": [
    "So the first letter predicted after the seed sequence is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6971,
     "status": "ok",
     "timestamp": 1613538410022,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "ErPPRZ-4AIt5",
    "outputId": "ab74b69d-bdd6-4d7d-fc12-a2ad04a99458"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6964,
     "status": "ok",
     "timestamp": 1613538410023,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "cLexXeVQAIza"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51684,
     "status": "ok",
     "timestamp": 1613538454748,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "BE7FR8en_uG3",
    "outputId": "073fe9fc-8225-4372-ccba-e26dda5ea2ff"
   },
   "outputs": [],
   "source": [
    "# Put all predicted characters in a list, then convert to a string later.\n",
    "complete_predicted_text =[]\n",
    "\n",
    "# Generate 1000 characters\n",
    "for i in range(600):\n",
    "    # reshape to 1 row, sequence length, and 1 for predicting one character as the target\n",
    "    temp_x = np.reshape(X_seeded, (1, len(X_seeded) , 1))\n",
    "    # normalize/scale the data by dividing by the length of the character list.\n",
    "    temp_x = temp_x / len(chars)\n",
    "    prediction = model.predict(temp_x, verbose=0)\n",
    "    complete_predicted_text.append(indices_char[np.argmax(prediction)])\n",
    "\n",
    "    # After predicting, add this character's numeric value on to the randomly\n",
    "    # chose seed string, and use this for another prediction\n",
    "    X_seeded.append(np.argmax(prediction))\n",
    "\n",
    "    # Move the seeded text up one character, so create a new sequence\n",
    "    X_seeded = X_seeded[1:len(X_seeded)]\n",
    "\n",
    "\n",
    "#print (complete_predicted_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "le8p2x7pP35N"
   },
   "source": [
    "The predicted results are a list of characters, so convert into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51677,
     "status": "ok",
     "timestamp": 1613538454748,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "F9xdtOGE_-8p",
    "outputId": "d825a21f-5e66-478e-eb9b-beb7b3bd58ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['his book Liespotting no one wants to meet me in person anymore no no no no no. T->h th toe to the toe to toe th the  Se',\n",
       " 'the the th te tee toe axd I woe thu to the to the wo to the to th to I  5T Iq t to the thx to th to te t te the toete',\n",
       " 'In toe to qoe to t ae to toe to th F Od to te wh th th to te toe th to a teoe toe to  I2 a  I wo te I nan  02n jo the to',\n",
       " 'th toe wo to wo N wo I no toe thet   Hh to to to to to woe to th th the toe th I woe th Iod I ao tou th tee th th to toe',\n",
       " 'tee th to to toe to the toe tee the toe toe  An th th  Vh whe to te the th th te to toe th to we th to the  To th toe to',\n",
       " 'I bo th the D wou to te to  In whx te te the  So I se th I we to th to th the to']"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_string = ''.join(complete_predicted_text)\n",
    "\n",
    "# Wrap to 120 characters just so I can visually compare to the original string.\n",
    "textwrap.wrap(seed_string + '->'+ predicted_string, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51672,
     "status": "ok",
     "timestamp": 1613538454749,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "QsIg_Zg8U487",
    "outputId": "740e0b8c-5879-48d4-b85d-975b3d316626"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['his book Liespotting no one wants to meet me in person anymore no no no no no. They say Its okay well email you.  I cant',\n",
       " 'even get a coffee date at Starbucks. My husbands like Honey deception? Maybe you could have focused on cooking. How',\n",
       " 'about French cooking? So before I get started what Im going to do is Im going to clarify my goal for you which is not to',\n",
       " 'teach a game of Gotcha. Liespotters arent those nitpicky kids those kids in the back of the room that are shouting',\n",
       " 'Gotcha! Gotcha! Your eyebrow twitched. You flared your nostril. I watch that TV show Lie To Me. I know youre lying. No',\n",
       " 'liespotters are armed with scientific knowledge of how to spot deception. They use it to get to the truth and they do',\n",
       " 'what mature leaders do everyday they have difficult conversations with difficult people sometimes during very difficult',\n",
       " 'times. And they start up that path by accepting a core proposition and that proposition is the  Lying is a cooperative',\n",
       " 'act. Think about it a lie has no power whatsoever by its mere utterance. Its power emerges when someone else agrees to',\n",
       " 'believe the lie. So I know it may sound like tough love but look if at some point you got lied to its because you agreed',\n",
       " 'to get lied to. Truth number one about  Lyings a cooperative act. Now not all lies are harmful. Sometimes were willing',\n",
       " 'participants in deception for the sake of social dignity maybe to keep a secret that should be kept secret secret. We',\n",
       " 'say Nice song. Honey you dont look fat in that no. Or we say favorite of the digiratti You know I just fished that email',\n",
       " 'out of my Spam folder. So sorry. But there are times when we are unwilling participants in deception. And that can have',\n",
       " 'dramatic costs for us. Last year saw 997 billion dollars in corporate fraud alone in the United States. Thats an eyelash',\n",
       " 'under a trillion dollars. Thats seven percent of revenues. Deception can cost billions. Think Enron Madoff the mortgage',\n",
       " 'crisis. Or in the case of double agents and traitors like Robert Hanssen or Aldrich Ames lie']"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the original seed string to see what came after it\n",
    "original_paragraph = corpus[corpus.find(seed_string): corpus.find(seed_string) + 2000]\n",
    "\n",
    "textwrap.wrap(original_paragraph, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51666,
     "status": "ok",
     "timestamp": 1613538454749,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "MSWX94UK8WhN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51661,
     "status": "ok",
     "timestamp": 1613538454749,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "0MKrmY6C8VFL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51657,
     "status": "ok",
     "timestamp": 1613538454750,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "HNC6Lxt__9N-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51652,
     "status": "ok",
     "timestamp": 1613538454750,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "SiYaK6B_AHZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNa5+T0gWfZd3GC6w1ulZ0Z",
   "collapsed_sections": [],
   "name": "Ted Talk Load Model and Predict",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
