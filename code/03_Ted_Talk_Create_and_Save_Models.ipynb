{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8VMnuH-l2o_"
   },
   "source": [
    "### Ted Talks Text Generator\n",
    "#### Create models\n",
    "\n",
    "Generate using a character based model.\n",
    "\n",
    "The code is this notebook is a partial modification of several tutorials, blog posts and YouTube videos. The main sources include:\n",
    "* [Text Generation With LSTM Recurrent Neural Networks in Python with Keras](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/) by Dr. Jason Brownlee\n",
    "* [Text Generation with Python and TensorFlow/Keras](https://stackabuse.com/text-generation-with-python-and-tensorflow-keras/) by Dan Nelson\n",
    "* YouTube: [167 - Text prediction using LSTM (English text)](https://youtu.be/zyCpntcVKSo?t=2) by Sreenivas B.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "R6RJL04YvQ1J"
   },
   "outputs": [],
   "source": [
    "# Uncomment if running on Google Colab to view runtime information.\n",
    "\n",
    "# gpu_info = !nvidia-smi\n",
    "# gpu_info = '\\n'.join(gpu_info)\n",
    "# if gpu_info.find('failed') >= 0:\n",
    "#   print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "#   print('and then re-execute this cell.')\n",
    "# else:\n",
    "#   print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5sMrWjFpv4Od"
   },
   "outputs": [],
   "source": [
    "# from psutil import virtual_memory\n",
    "# ram_gb = virtual_memory().total / 1e9\n",
    "# print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "# if ram_gb < 20:\n",
    "#   print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
    "#   print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "#   print('re-execute this cell.')\n",
    "# else:\n",
    "#   print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OLpQP9ZPs3Z8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "waLxIXEXmCoW"
   },
   "outputs": [],
   "source": [
    "# # Attach to my Google drive so I can save the csv file later\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "RoYqpZYpbvvH"
   },
   "outputs": [],
   "source": [
    "#tag_name = 'all_transcripts'\n",
    "#tag_name = 'brain'\n",
    "#tag_name = 'business'\n",
    "#tag_name = 'creativity'\n",
    "#tag_name = 'culture'\n",
    "#tag_name = 'psychology'\n",
    "#tag_name = 'science'\n",
    "tag_name = 'all'\n",
    "\n",
    "lower_corpus = False\n",
    "\n",
    "if lower_corpus:\n",
    "    corpus_file_name = tag_name + '_lowercase'\n",
    "else:\n",
    "    corpus_file_name = tag_name + '_sentence_case'\n",
    "\n",
    "# This switch makes it easier running locally or in a Google Colab environment\n",
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    root_path = '/content/drive/MyDrive/ted/'\n",
    "    data_path = f'{root_path}'\n",
    "else:\n",
    "    root_path = '../'\n",
    "    data_path = f'{root_path}data/'\n",
    "    \n",
    "model_path = f'{root_path}models/'\n",
    "logs_path = f'{root_path}logs/'\n",
    "    \n",
    "sequence_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "V1ljkpt0l1kx"
   },
   "outputs": [],
   "source": [
    "# if on Google Colab, load transcripts file.\n",
    "# with open(f'/content/drive/MyDrive/ted/{corpus_file_name}.txt') as f:\n",
    "#   corpus = f.read()\n",
    "# f.close()\n",
    "\n",
    "# if run locally:\n",
    "with open(f'{data_path}{corpus_file_name}.txt', encoding='utf-8') as f:\n",
    "    corpus = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "K8pyPFcnmCD9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Good morning. How are you?  Good. It's been great, hasn't it? I've been blown away by the whole thing. In fact, I'm leaving.  There have been three themes running through the conference, which are relevant to what I want to talk about. One is the extraordinary evidence of human creativity in all of the presentations that we've had and in all of the people here; just the variety of it and the range of it. The second is that it's put us in a place where we have no idea what's going to happen in te\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDIMVXs-kwz3"
   },
   "source": [
    "The code below is used in almost every article I have seen about LSTM for text generation, but this snippet is adapted from :\n",
    "https://www.kaggle.com/mrisdal/intro-to-lstms-w-keras-gpu-for-text-generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '$', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'è', 'é', '–', '’', '“', '”', '…', '♫']\n"
     ]
    }
   ],
   "source": [
    "all_chars = sorted(list(set(corpus)))\n",
    "\n",
    "#remove most punctuation, but leave spaces, exclamation points, and periods\n",
    "list_to_remove = ['\"', '&', '-', ',', \"'\", '/', ';',  '—', '%','[', ']' ]\n",
    "chars = [character for character in all_chars if character not in list_to_remove]\n",
    "print(chars)\n",
    "# hat tip to this post for the idea of removing one list from another\n",
    "# https://www.geeksforgeeks.org/python-remove-all-values-from-a-list-present-in-other-list/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I were to refit all of my neural network models in the future, I would add more of these unusual characters to the `list_to_remove` list to strip them out of the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all unwanted characters from the original corpus\n",
    "corpus_list = [character for character in corpus if character not in list_to_remove]\n",
    "\n",
    "# Re-join all letters back into a single string as the updated corpus\n",
    "corpus = ''.join(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "KW8k2n7piPca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in the corpus: 75\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique characters in the corpus:', len(chars))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "vwPryvRueRtT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '$': 2, '.': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, '?': 14, 'A': 15, 'B': 16, 'C': 17, 'D': 18, 'E': 19, 'F': 20, 'G': 21, 'H': 22, 'I': 23, 'J': 24, 'K': 25, 'L': 26, 'M': 27, 'N': 28, 'O': 29, 'P': 30, 'Q': 31, 'R': 32, 'S': 33, 'T': 34, 'U': 35, 'V': 36, 'W': 37, 'X': 38, 'Y': 39, 'Z': 40, 'a': 41, 'b': 42, 'c': 43, 'd': 44, 'e': 45, 'f': 46, 'g': 47, 'h': 48, 'i': 49, 'j': 50, 'k': 51, 'l': 52, 'm': 53, 'n': 54, 'o': 55, 'p': 56, 'q': 57, 'r': 58, 's': 59, 't': 60, 'u': 61, 'v': 62, 'w': 63, 'x': 64, 'y': 65, 'z': 66, 'è': 67, 'é': 68, '–': 69, '’': 70, '“': 71, '”': 72, '…': 73, '♫': 74}\n"
     ]
    }
   ],
   "source": [
    "# Show character to index mapping\n",
    "print (char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "RqMa6shPiQrd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: '!', 2: '$', 3: '.', 4: '0', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: '?', 15: 'A', 16: 'B', 17: 'C', 18: 'D', 19: 'E', 20: 'F', 21: 'G', 22: 'H', 23: 'I', 24: 'J', 25: 'K', 26: 'L', 27: 'M', 28: 'N', 29: 'O', 30: 'P', 31: 'Q', 32: 'R', 33: 'S', 34: 'T', 35: 'U', 36: 'V', 37: 'W', 38: 'X', 39: 'Y', 40: 'Z', 41: 'a', 42: 'b', 43: 'c', 44: 'd', 45: 'e', 46: 'f', 47: 'g', 48: 'h', 49: 'i', 50: 'j', 51: 'k', 52: 'l', 53: 'm', 54: 'n', 55: 'o', 56: 'p', 57: 'q', 58: 'r', 59: 's', 60: 't', 61: 'u', 62: 'v', 63: 'w', 64: 'x', 65: 'y', 66: 'z', 67: 'è', 68: 'é', 69: '–', 70: '’', 71: '“', 72: '”', 73: '…', 74: '♫'}\n"
     ]
    }
   ],
   "source": [
    "# Show index to character mapping\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ns5RcDesiQzZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input corpus contains 267,106 characters.\n"
     ]
    }
   ],
   "source": [
    "print (f'The input corpus contains {len(corpus):,} characters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85NHcjWuiQ7D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXgbFM-46jrS"
   },
   "source": [
    "The model will use arbitrary length of characters, e.g. 40, and then predict the next character that will appear (the 41st).\n",
    "\n",
    "I would like to change this sequence length in different models, to see how it might affect the model's performance.\n",
    "\n",
    "Larger might be better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNWrhS2LJkOt"
   },
   "source": [
    "Loop through the corpus, creating segments of characters, plus a segment of a single character that would appear after it. These segments are then converted into their respective digits, and loaded into X\n",
    "\n",
    "In addition, create a list of target values. The target, y, is a single text character, and is also converted into a corresponding numeric value.\n",
    "\n",
    "For example, in the sentence **\"Welcome to my TED talk.\"**, a model uses a sequence length of 8, would use the first 8 characters as its input variables, in order to predict the 9th character.\n",
    "\n",
    "![Image](../images/welcome_1.png)\n",
    "\n",
    "Similar to a sliding window, the next sequence of characters is moved over by one, in order to add a row for the next sample.\n",
    "\n",
    "![Image](../images/welcome_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "uPWsaG39Si52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good morning. How are you?  Good. Its be'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "pB06ivEKOa2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ood morning. How are you?  Good. Its bee'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "QN8H5lmRPzV8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "z4bwf70jiRIF"
   },
   "outputs": [],
   "source": [
    "# For future modeling, we could try to offset the sequences by more than one\n",
    "# letter. For now the model will look at every sequence right after another.\n",
    "step = 1\n",
    "\n",
    "X_numeric_list = []\n",
    "y_numeric_list = []\n",
    "\n",
    "\n",
    "for i in range (0, len(corpus) - sequence_length, step):\n",
    "    # To find X when still as characters, loop through and extract\n",
    "    # a sequence for example, from the 2nd to the 42nd, as in corpus[1:41] since \n",
    "    # the string index is zero-based\n",
    "    X_char_sequence = corpus[i:i + sequence_length]  #exclusive\n",
    "    y_char = corpus[i + sequence_length]\n",
    "\n",
    "    # Convert the X character sequence into a list of integers, using the \n",
    "    # dictionary created above.\n",
    "    X_numeric_list.append( [char_indices[letter] for letter in X_char_sequence])\n",
    "    # Also convert target letter y to it's corresponding numeric value in the\n",
    "    # dictionary\n",
    "    y_numeric_list.append(char_indices[y_char])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "OAIoz7XIXIWV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 55, 55, 44, 0, 53, 55, 58, 54, 49, 54, 47, 3, 0, 22, 55, 63, 0, 41, 58, 45, 0, 65, 55, 61, 14, 0, 0, 21, 55, 55, 44, 3, 0, 23, 60, 59, 0, 42, 45]\n",
      "[55, 55, 44, 0, 53, 55, 58, 54, 49, 54, 47, 3, 0, 22, 55, 63, 0, 41, 58, 45, 0, 65, 55, 61, 14, 0, 0, 21, 55, 55, 44, 3, 0, 23, 60, 59, 0, 42, 45, 45]\n"
     ]
    }
   ],
   "source": [
    "# Look at the first two converted sequences\n",
    "print ( X_numeric_list[0])\n",
    "print ( X_numeric_list[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "W_WYfvRUXLd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print ( y_numeric_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "pUBI2jozXYT1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "PhR81VtiXzyJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good morning. How are you?  Good. Its been '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:43]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2X_QDPSqYAmR"
   },
   "source": [
    "---\n",
    "An example of the first record of X (in text form):<br>\n",
    "`Good morning. How are you?  Good. Its be`\n",
    "<br>\n",
    "And its corresponding target (y) (in text form):<br>\n",
    "`e`\n",
    "\n",
    "After being converted to numeric values, the first record for X:<br>\n",
    "`[21, 55, 55, 44, 0, 53, 55, 58, 54, 49, 54, 47, 3, 0, 22, 55, 63, 0, 41, 58, 45, 0, 65, 55, 61, 14, 0, 0, 21, 55, 55, 44, 3, 0, 23, 60, 59, 0, 42, 45]`\n",
    "\n",
    "And it corresponding target (y):<br>\n",
    "`45`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "nkX8BKMMX4hh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 267,066 entries in X_numeric_list\n"
     ]
    }
   ],
   "source": [
    "print (f'There are {len(X_numeric_list):,} entries in X_numeric_list') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tn3uKqnJasUf"
   },
   "source": [
    "An LSTM model needs the X data to be in 3 dimensions:\n",
    "* Samples (number of rows)\n",
    "* Time steps (this implies time series. In this example this corresponds to the sequence_length)\n",
    "* Features (the target, or y variable)\n",
    "\n",
    "This [blog post by Dr. John Brownlee](https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/) contains a longer explanation, which I paraphrased here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "qH7OG0kAYALM"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "# Samples is the total number of 40 character text fragments created above\n",
    "# Time step is the sequence length, which is this case is 40, but might change\n",
    "# in other model variations\n",
    "# Feature is one, since the model is predicting one character at a time\n",
    "X = np.reshape(X_numeric_list, (len(X_numeric_list), sequence_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WYTRXPhbarU0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267066, 40, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "lrG9AduNY47g"
   },
   "outputs": [],
   "source": [
    "# normalize/scale the data by dividing by the length of the character list.\n",
    "X = X / len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bhvp9pN5_txN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28      ],\n",
       "       [0.73333333],\n",
       "       [0.73333333],\n",
       "       [0.58666667],\n",
       "       [0.        ],\n",
       "       [0.70666667],\n",
       "       [0.73333333],\n",
       "       [0.77333333],\n",
       "       [0.72      ],\n",
       "       [0.65333333],\n",
       "       [0.72      ],\n",
       "       [0.62666667],\n",
       "       [0.04      ],\n",
       "       [0.        ],\n",
       "       [0.29333333],\n",
       "       [0.73333333],\n",
       "       [0.84      ],\n",
       "       [0.        ],\n",
       "       [0.54666667],\n",
       "       [0.77333333],\n",
       "       [0.6       ],\n",
       "       [0.        ],\n",
       "       [0.86666667],\n",
       "       [0.73333333],\n",
       "       [0.81333333],\n",
       "       [0.18666667],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.28      ],\n",
       "       [0.73333333],\n",
       "       [0.73333333],\n",
       "       [0.58666667],\n",
       "       [0.04      ],\n",
       "       [0.        ],\n",
       "       [0.30666667],\n",
       "       [0.8       ],\n",
       "       [0.78666667],\n",
       "       [0.        ],\n",
       "       [0.56      ],\n",
       "       [0.6       ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first value of X\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cqa6ZNx4AQwE"
   },
   "source": [
    "Even thought the values for the target variable are integers, they are essentially labels for the predicted characters. They are one-hot encoded using the to_categorical function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "XqS9wPlW_t5F"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y_numeric_list)\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lb1V-QYZFdoe"
   },
   "source": [
    "---\n",
    "### Create LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDkWLh9rbt8u"
   },
   "source": [
    "This [blog post](https://towardsdatascience.com/choosing-the-right-hyperparameters-for-a-simple-lstm-using-keras-f8e9ed76f046) has a rule of thumb of how many nodes to include in an LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "2mTUmOiObqAv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of hidden nodes is 2000.\n"
     ]
    }
   ],
   "source": [
    "hidden_nodes = int(2/3 * (len(chars) * sequence_length))\n",
    "print(f\"The number of hidden nodes is {hidden_nodes}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6JSetPskixm"
   },
   "source": [
    "Use of ModelCheckPoint to save the model's progress example as described in the [TensorFlow documentation.](https://www.tensorflow.org/tutorials/keras/save_and_load#checkpoint_callback_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "3AE-lxQMkge2"
   },
   "outputs": [],
   "source": [
    "#Set a path to save the checkpoint files for this model\n",
    "checkpoint_path = f'{model_path}{corpus_file_name}/{corpus_file_name}.ckpt'\n",
    "checkpoint_dir = f'{model_path}{corpus_file_name}/'\n",
    "\n",
    "# Create a callback that saves the model's weights every 50 fits\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "R1tBdmEw_t-b"
   },
   "outputs": [],
   "source": [
    "# # define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(500, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(16))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy','Recall','Precision'])\n",
    "\n",
    "# # Save the weights using the `checkpoint_path` format\n",
    "# model.save_weights(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store this for a log file name\n",
    "input_nodes_count = model.layers[0].output_shape[len(model.layers[2].output_shape)-1]\n",
    "input_nodes_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the last value of shape, which contains how many nodes or output values to either the next layer, or the final Dense layer\n",
    "layer_2_nodes_count=model.layers[2].output_shape[len(model.layers[2].output_shape)-1]\n",
    "layer_2_nodes_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 500)               1004000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 75)                37575     \n",
      "=================================================================\n",
      "Total params: 1,041,575\n",
      "Trainable params: 1,041,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = load_model(f'{root_path}/models/ted_model_{tag_name}')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hat tip to this stack overflow post for the CSV Logger bit:\n",
    "# https://stackoverflow.com/questions/41061457/keras-how-to-save-the-training-history-attribute-of-the-history-object\n",
    "\n",
    "model_cb = ModelCheckpoint(filepath=checkpoint_path)\n",
    "history_cb = CSVLogger(f'{logs_path}/{corpus_file_name}_{input_nodes_count}_{layer_2_nodes_count}_log.csv', separator=\",\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6GmU5hK_uAk",
    "outputId": "daa23890-2c55-4826-f9ef-330f6d8e5e2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2671/2671 [==============================] - 592s 222ms/step - loss: 1.1410 - accuracy: 0.6470 - recall: 0.5200 - precision: 0.8207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "2671/2671 [==============================] - 563s 211ms/step - loss: 1.1238 - accuracy: 0.6516 - recall: 0.5268 - precision: 0.8221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "2671/2671 [==============================] - 577s 216ms/step - loss: 1.1121 - accuracy: 0.6550 - recall: 0.5313 - precision: 0.8213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "2671/2671 [==============================] - 593s 222ms/step - loss: 1.0959 - accuracy: 0.6592 - recall: 0.5386 - precision: 0.8242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "2671/2671 [==============================] - 586s 219ms/step - loss: 1.0788 - accuracy: 0.6647 - recall: 0.5451 - precision: 0.8253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "2671/2671 [==============================] - 574s 215ms/step - loss: 1.0671 - accuracy: 0.6678 - recall: 0.5504 - precision: 0.8264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "2671/2671 [==============================] - 591s 221ms/step - loss: 1.0478 - accuracy: 0.6733 - recall: 0.5584 - precision: 0.8277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "2671/2671 [==============================] - 621s 233ms/step - loss: 1.0384 - accuracy: 0.6756 - recall: 0.5623 - precision: 0.8273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "2671/2671 [==============================] - 612s 229ms/step - loss: 1.0229 - accuracy: 0.6797 - recall: 0.5676 - precision: 0.8288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "2671/2671 [==============================] - 637s 238ms/step - loss: 1.0083 - accuracy: 0.6844 - recall: 0.5733 - precision: 0.8307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "2671/2671 [==============================] - 600s 225ms/step - loss: 0.9922 - accuracy: 0.6892 - recall: 0.5806 - precision: 0.8315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "2671/2671 [==============================] - 601s 225ms/step - loss: 0.9842 - accuracy: 0.6909 - recall: 0.5842 - precision: 0.8317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "2671/2671 [==============================] - 573s 215ms/step - loss: 0.9687 - accuracy: 0.6953 - recall: 0.5897 - precision: 0.8330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "2671/2671 [==============================] - 611s 229ms/step - loss: 0.9578 - accuracy: 0.6985 - recall: 0.5948 - precision: 0.8336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "2671/2671 [==============================] - 622s 233ms/step - loss: 0.9466 - accuracy: 0.7005 - recall: 0.5993 - precision: 0.8338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "2671/2671 [==============================] - 618s 231ms/step - loss: 0.9342 - accuracy: 0.7049 - recall: 0.6034 - precision: 0.8344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "2671/2671 [==============================] - 604s 226ms/step - loss: 0.9245 - accuracy: 0.7080 - recall: 0.6086 - precision: 0.8367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "2671/2671 [==============================] - 630s 236ms/step - loss: 0.9095 - accuracy: 0.7116 - recall: 0.6137 - precision: 0.8380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "2671/2671 [==============================] - 665s 249ms/step - loss: 0.9022 - accuracy: 0.7135 - recall: 0.6176 - precision: 0.8364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "2671/2671 [==============================] - 645s 241ms/step - loss: 0.8885 - accuracy: 0.7170 - recall: 0.6226 - precision: 0.8383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "2671/2671 [==============================] - 599s 224ms/step - loss: 0.8784 - accuracy: 0.7208 - recall: 0.6283 - precision: 0.8404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "2671/2671 [==============================] - 579s 217ms/step - loss: 0.8680 - accuracy: 0.7240 - recall: 0.6318 - precision: 0.8404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "2671/2671 [==============================] - 620s 232ms/step - loss: 0.8590 - accuracy: 0.7259 - recall: 0.6348 - precision: 0.8415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "2671/2671 [==============================] - 606s 227ms/step - loss: 0.8490 - accuracy: 0.7292 - recall: 0.6404 - precision: 0.8421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "2671/2671 [==============================] - 606s 227ms/step - loss: 0.8388 - accuracy: 0.7322 - recall: 0.6436 - precision: 0.8432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "2671/2671 [==============================] - 591s 221ms/step - loss: 0.8302 - accuracy: 0.7349 - recall: 0.6481 - precision: 0.8441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "2671/2671 [==============================] - 591s 221ms/step - loss: 0.8241 - accuracy: 0.7369 - recall: 0.6506 - precision: 0.8452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "2671/2671 [==============================] - 584s 219ms/step - loss: 0.8151 - accuracy: 0.7390 - recall: 0.6539 - precision: 0.8446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "2671/2671 [==============================] - 601s 225ms/step - loss: 0.8066 - accuracy: 0.7412 - recall: 0.6571 - precision: 0.8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "2671/2671 [==============================] - 600s 225ms/step - loss: 0.7965 - accuracy: 0.7440 - recall: 0.6619 - precision: 0.8471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "2671/2671 [==============================] - 605s 227ms/step - loss: 0.7882 - accuracy: 0.7474 - recall: 0.6658 - precision: 0.8482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "2671/2671 [==============================] - 585s 219ms/step - loss: 0.7804 - accuracy: 0.7487 - recall: 0.6685 - precision: 0.8483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "2671/2671 [==============================] - 610s 229ms/step - loss: 0.7739 - accuracy: 0.7517 - recall: 0.6725 - precision: 0.8495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "2671/2671 [==============================] - 579s 217ms/step - loss: 0.7692 - accuracy: 0.7519 - recall: 0.6740 - precision: 0.8496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "2671/2671 [==============================] - 554s 207ms/step - loss: 0.7588 - accuracy: 0.7556 - recall: 0.6777 - precision: 0.8509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "2671/2671 [==============================] - 550s 206ms/step - loss: 0.7535 - accuracy: 0.7573 - recall: 0.6809 - precision: 0.8513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "2671/2671 [==============================] - 517s 194ms/step - loss: 0.7414 - accuracy: 0.7604 - recall: 0.6858 - precision: 0.8536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "2671/2671 [==============================] - 506s 189ms/step - loss: 0.7356 - accuracy: 0.7616 - recall: 0.6876 - precision: 0.8519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "2671/2671 [==============================] - 493s 185ms/step - loss: 0.7296 - accuracy: 0.7643 - recall: 0.6902 - precision: 0.8541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "2671/2671 [==============================] - 507s 190ms/step - loss: 0.7246 - accuracy: 0.7654 - recall: 0.6927 - precision: 0.8540s - loss: 0.7237 - accuracy: 0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "2671/2671 [==============================] - 499s 187ms/step - loss: 0.7145 - accuracy: 0.7690 - recall: 0.6971 - precision: 0.8561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "2671/2671 [==============================] - 498s 186ms/step - loss: 0.7098 - accuracy: 0.7696 - recall: 0.6993 - precision: 0.8559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "2671/2671 [==============================] - 495s 185ms/step - loss: 0.7001 - accuracy: 0.7731 - recall: 0.7036 - precision: 0.8573s - loss: 0.6998 - accuracy: 0.7732 - recall: 0.7037 - preci\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "2671/2671 [==============================] - 489s 183ms/step - loss: 0.6990 - accuracy: 0.7735 - recall: 0.7040 - precision: 0.8567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "2671/2671 [==============================] - 484s 181ms/step - loss: 0.6935 - accuracy: 0.7748 - recall: 0.7068 - precision: 0.8570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "2671/2671 [==============================] - 477s 178ms/step - loss: 0.6827 - accuracy: 0.7785 - recall: 0.7106 - precision: 0.8593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "2671/2671 [==============================] - 472s 177ms/step - loss: 0.6835 - accuracy: 0.7778 - recall: 0.7105 - precision: 0.8580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "2671/2671 [==============================] - 482s 180ms/step - loss: 0.6748 - accuracy: 0.7807 - recall: 0.7140 - precision: 0.8593s - loss: 0.6748 - accuracy: 0.7807 - recall: 0.7140 - preci\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "2671/2671 [==============================] - 493s 184ms/step - loss: 0.6709 - accuracy: 0.7814 - recall: 0.7167 - precision: 0.8591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "2671/2671 [==============================] - 477s 179ms/step - loss: 0.6671 - accuracy: 0.7823 - recall: 0.7180 - precision: 0.8593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_sentence_case\\all_sentence_case.ckpt\\assets\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=50, batch_size=100, callbacks=[model_cb, history_cb], workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "SjmfANPRCiSg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model:../models/all_500_75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_500_75\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/all_500_75\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model to my Google Drive so I can load it later from another notebook\n",
    "#model.save(f'/content/drive/MyDrive/ted/models/ted_model_{tag_name}')\n",
    "\n",
    "print(f'Saving model:{model_path}{tag_name}_{input_nodes_count}_{layer_2_nodes_count}')\n",
    "model.save(f'{model_path}{tag_name}_{input_nodes_count}_{layer_2_nodes_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "0MKrmY6C8VFL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'recall', 'precision'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['recall'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.legend( loc='upper left')\n",
    "#plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SiYaK6B_AHZ_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Ted Talk Create and Save Models",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
