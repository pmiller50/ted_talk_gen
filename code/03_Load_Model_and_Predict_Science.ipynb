{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8VMnuH-l2o_"
   },
   "source": [
    "TED talk text generator\n",
    "\n",
    "Generate using a character based model.\n",
    "\n",
    "The code is this notebook is a partial modification of several tutorials, blog posts and YouTube videos. The main sources include:\n",
    "* [Text Generation With LSTM Recurrent Neural Networks in Python with Keras](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/) by Dr. Jason Brownlee\n",
    "* [Text Generation with Python and TensorFlow/Keras](https://stackabuse.com/text-generation-with-python-and-tensorflow-keras/) by Dan Nelson\n",
    "* YouTube: [167 - Text prediction using LSTM (English text)](https://youtu.be/zyCpntcVKSo?t=2) by Sreenivas B.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1613538403438,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "OLpQP9ZPs3Z8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.train import latest_checkpoint\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "import random\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1613538403660,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "waLxIXEXmCoW",
    "outputId": "c9837e2d-5c4e-489f-9030-e6c18a9bcd1a"
   },
   "outputs": [],
   "source": [
    "# Attach to my Google drive so I can save the csv file later\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1613538403660,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "1ygYMqkOddlx"
   },
   "outputs": [],
   "source": [
    "#tag_name = 'all_transcripts'\n",
    "#tag_name = 'brain'\n",
    "tag_name = 'business'\n",
    "#tag_name = 'creativity'\n",
    "#tag_name = 'culture'\n",
    "#tag_name = 'psychology'\n",
    "#tag_name = 'science'\n",
    "\n",
    "lower_corpus = False\n",
    "\n",
    "if lower_corpus:\n",
    "    corpus_file_name = tag_name + '_lowercase'\n",
    "else:\n",
    "    corpus_file_name = tag_name + '_sentence_case'\n",
    "\n",
    "# This switch makes it easier running locally or in a Google Colab environment\n",
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    root_path = '/content/drive/MyDrive/ted/'\n",
    "else:\n",
    "    root_path = '../data/'\n",
    "    \n",
    "sequence_length = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "executionInfo": {
     "elapsed": 863,
     "status": "ok",
     "timestamp": 1613538403661,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "V1ljkpt0l1kx"
   },
   "outputs": [],
   "source": [
    "with open(f'{root_path}{corpus_file_name}.txt', encoding='utf-8') as f:\n",
    "    corpus = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 1322,
     "status": "ok",
     "timestamp": 1613538404130,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "K8pyPFcnmCD9",
    "outputId": "3813cc1e-6871-4766-9709-f5e11b5f7660"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So I want to start by offering you a free no-tech life hack, and all it requires of you is  that you change your posture for two minutes. But before I give it away, I want to ask you to right now do a little audit of your body and what you're doing with your body. So how many of you are sort of making yourselves smaller? Maybe you're hunching, crossing your legs, maybe wrapping your ankles. Sometimes we hold onto our arms like this. Sometimes we spread out.  I see you. So I want you to pay atten\""
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDIMVXs-kwz3"
   },
   "source": [
    "The code below is used in almost every article I have seen about LSTM for text generation, but this snippet is adapted from :\n",
    "https://www.kaggle.com/mrisdal/intro-to-lstms-w-keras-gpu-for-text-generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chars = sorted(list(set(corpus)))\n",
    "\n",
    "#remove most punctuation, but leave spaces, exclamation points, and periods\n",
    "list_to_remove = ['\"', '&', '-', ',', \"'\", '/', ';',  'â€”']\n",
    "\n",
    "chars = [character for character in all_chars if character not in list_to_remove]\n",
    "# print(chars)\n",
    "# # hat tip to this post for the idea of removing one list from another\n",
    "# # https://www.geeksforgeeks.org/python-remove-all-values-from-a-list-present-in-other-list/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all unwanted characters from the original corpus\n",
    "corpus_list = [character for character in corpus if character not in list_to_remove]\n",
    "\n",
    "# Re-join all letters back into a single string as the updated corpus\n",
    "corpus = ''.join(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1313,
     "status": "ok",
     "timestamp": 1613538404131,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "KW8k2n7piPca",
    "outputId": "70c7cd09-9650-4e03-8fb5-561532a8aeed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in the corpus: 66\n"
     ]
    }
   ],
   "source": [
    "# If running models with punctuation removed, leave commented out\n",
    "# chars = sorted(list(set(corpus)))\n",
    "\n",
    "print('Number of unique characters in the corpus:', len(chars))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1304,
     "status": "ok",
     "timestamp": 1613538404131,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "vwPryvRueRtT",
    "outputId": "a90beecb-f0fc-48ef-e803-c04afc88d5ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '%': 2, '.': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, '?': 14, 'A': 15, 'B': 16, 'C': 17, 'D': 18, 'E': 19, 'F': 20, 'G': 21, 'H': 22, 'I': 23, 'J': 24, 'K': 25, 'L': 26, 'M': 27, 'N': 28, 'O': 29, 'P': 30, 'Q': 31, 'R': 32, 'S': 33, 'T': 34, 'U': 35, 'V': 36, 'W': 37, 'Y': 38, 'Z': 39, 'a': 40, 'b': 41, 'c': 42, 'd': 43, 'e': 44, 'f': 45, 'g': 46, 'h': 47, 'i': 48, 'j': 49, 'k': 50, 'l': 51, 'm': 52, 'n': 53, 'o': 54, 'p': 55, 'q': 56, 'r': 57, 's': 58, 't': 59, 'u': 60, 'v': 61, 'w': 62, 'x': 63, 'y': 64, 'z': 65}\n"
     ]
    }
   ],
   "source": [
    "# Show character to index mapping\n",
    "print (char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1294,
     "status": "ok",
     "timestamp": 1613538404132,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "RqMa6shPiQrd",
    "outputId": "6965acf5-10cf-4624-efde-abb4f61eeb4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: '!', 2: '%', 3: '.', 4: '0', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: '?', 15: 'A', 16: 'B', 17: 'C', 18: 'D', 19: 'E', 20: 'F', 21: 'G', 22: 'H', 23: 'I', 24: 'J', 25: 'K', 26: 'L', 27: 'M', 28: 'N', 29: 'O', 30: 'P', 31: 'Q', 32: 'R', 33: 'S', 34: 'T', 35: 'U', 36: 'V', 37: 'W', 38: 'Y', 39: 'Z', 40: 'a', 41: 'b', 42: 'c', 43: 'd', 44: 'e', 45: 'f', 46: 'g', 47: 'h', 48: 'i', 49: 'j', 50: 'k', 51: 'l', 52: 'm', 53: 'n', 54: 'o', 55: 'p', 56: 'q', 57: 'r', 58: 's', 59: 't', 60: 'u', 61: 'v', 62: 'w', 63: 'x', 64: 'y', 65: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# Show index to character mapping\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1286,
     "status": "ok",
     "timestamp": 1613538404132,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "ns5RcDesiQzZ",
    "outputId": "fc7676a5-4d17-4b11-e18c-929b51c72f50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input corpus contains 68,253 characters.\n"
     ]
    }
   ],
   "source": [
    "print (f'The input corpus contains {len(corpus):,} characters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1278,
     "status": "ok",
     "timestamp": 1613538404132,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "85NHcjWuiQ7D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXgbFM-46jrS"
   },
   "source": [
    "The model will use arbitrary length of characters, e.g. 40, and then predict the next character that will appear (the 41st).\n",
    "\n",
    "I would like to change this sequence length in different models, to see how it might affect the model's performance.\n",
    "\n",
    "Larger might be better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1613538404133,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "CgLONw9RiRC-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNWrhS2LJkOt"
   },
   "source": [
    "Loop through the corpus, creating segments of 40 characters, plus a segment of a single character that would appear after it. These segments are then converted into their respective digits, and loaded into X\n",
    "\n",
    "In addition, create a list of target values. The target, y, is a single text character, and is also converted into a corresponding numeric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1265,
     "status": "ok",
     "timestamp": 1613538404133,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "uPWsaG39Si52",
    "outputId": "ec027126-9d6e-4bb4-cd0d-965a7c65f1ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So I want to start by offering you a free notech l'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1613538404133,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "pB06ivEKOa2f",
    "outputId": "7f8f681f-b956-4c94-a8d1-fed28e011bd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o I want to start by offering you a free'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1248,
     "status": "ok",
     "timestamp": 1613538404134,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "QN8H5lmRPzV8",
    "outputId": "ebd703f3-9fd8-4a71-f00a-791ff00b8ceb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "executionInfo": {
     "elapsed": 2091,
     "status": "ok",
     "timestamp": 1613538404984,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "z4bwf70jiRIF"
   },
   "outputs": [],
   "source": [
    "# For future modeling, we could try to offset the sequences by more than one\n",
    "# letter. For now the model will look at every sequence right after another.\n",
    "step = 1\n",
    "\n",
    "X_numeric_list = []\n",
    "y_numeric_list = []\n",
    "\n",
    "\n",
    "for i in range (0, len(corpus) - sequence_length, step):\n",
    "    # To find X when still as characters, loop through and extract\n",
    "    # a sequence for example, from the 2nd to the 42nd, as in corpus[1:41] since \n",
    "    # the string index is zero-based\n",
    "    X_char_sequence = corpus[i:i + sequence_length]  #exclusive\n",
    "    y_char = corpus[i + sequence_length]\n",
    "\n",
    "    # Convert the X character sequence into a list of integers, using the \n",
    "    # dictionary created above.\n",
    "    X_numeric_list.append( [char_indices[letter] for letter in X_char_sequence])\n",
    "    # Also convert target letter y to it's corresponding numeric value in the\n",
    "    # dictionary\n",
    "    y_numeric_list.append(char_indices[y_char])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2085,
     "status": "ok",
     "timestamp": 1613538404984,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "OAIoz7XIXIWV",
    "outputId": "1368effc-745f-4a2a-df82-09c0a57e1d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 54, 0, 23, 0, 62, 40, 53, 59, 0, 59, 54, 0, 58, 59, 40, 57, 59, 0, 41, 64, 0, 54, 45, 45, 44, 57, 48, 53, 46, 0, 64, 54, 60, 0, 40, 0, 45, 57, 44, 44, 0, 53, 54, 59, 44, 42, 47, 0, 51, 48, 45, 44, 0, 47, 40, 42, 50, 0, 40, 53, 43, 0, 40, 51, 51, 0, 48, 59, 0, 57, 44, 56, 60, 48, 57, 44, 58, 0, 54]\n",
      "[54, 0, 23, 0, 62, 40, 53, 59, 0, 59, 54, 0, 58, 59, 40, 57, 59, 0, 41, 64, 0, 54, 45, 45, 44, 57, 48, 53, 46, 0, 64, 54, 60, 0, 40, 0, 45, 57, 44, 44, 0, 53, 54, 59, 44, 42, 47, 0, 51, 48, 45, 44, 0, 47, 40, 42, 50, 0, 40, 53, 43, 0, 40, 51, 51, 0, 48, 59, 0, 57, 44, 56, 60, 48, 57, 44, 58, 0, 54, 45]\n"
     ]
    }
   ],
   "source": [
    "# Look at the first two converted sequences\n",
    "print ( X_numeric_list[0])\n",
    "print ( X_numeric_list[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2078,
     "status": "ok",
     "timestamp": 1613538404985,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "W_WYfvRUXLd8",
    "outputId": "41af6ff4-894e-4a89-b1e1-2439439852cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45, 0]\n"
     ]
    }
   ],
   "source": [
    "print ( y_numeric_list[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2071,
     "status": "ok",
     "timestamp": 1613538404985,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "pUBI2jozXYT1",
    "outputId": "5b950e77-26a9-45a7-d5df-a218ee01509e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2064,
     "status": "ok",
     "timestamp": 1613538404986,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "PhR81VtiXzyJ",
    "outputId": "ce15680c-aa72-4aee-9e48-230cfa3acddc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So I want to start by offering you a free n'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:43]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2X_QDPSqYAmR"
   },
   "source": [
    "This example is a little hard to follow, since we happened to be in the middle of the word 'been'. The letter e is mapped to 51.\n",
    "\n",
    "However the beginning of the sequence has been shifted by one as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2054,
     "status": "ok",
     "timestamp": 1613538404986,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "nkX8BKMMX4hh",
    "outputId": "7ff2f80c-cfd3-432f-b2ac-fbbf18042b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 68,173 entries in X_numeric_list\n"
     ]
    }
   ],
   "source": [
    "print (f'There are {len(X_numeric_list):,} entries in X_numeric_list') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tn3uKqnJasUf"
   },
   "source": [
    "An LSTM model needs the X data to be in 3 dimensions:\n",
    "* Samples (number of rows)\n",
    "* Time steps (this implies time series. In this example this corresponds to the sequence_length)\n",
    "* Features (the target, or y variable)\n",
    "\n",
    "This [blog post by Dr. John Brownlee](https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/) contains a longer explanation, which I paraphrased here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "executionInfo": {
     "elapsed": 2825,
     "status": "ok",
     "timestamp": 1613538405763,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "qH7OG0kAYALM"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "# Samples is the total number of 40 character text fragments created above\n",
    "# Time step is the sequence length, which is this case is 40, but might change\n",
    "# in other model variations\n",
    "# Feature is one, since the model is predicting one character at a time\n",
    "X = np.reshape(X_numeric_list, (len(X_numeric_list), sequence_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2819,
     "status": "ok",
     "timestamp": 1613538405763,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "WYTRXPhbarU0",
    "outputId": "3263bee5-a669-47b5-b02a-9f03e452b4cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68173, 80, 1)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "executionInfo": {
     "elapsed": 2813,
     "status": "ok",
     "timestamp": 1613538405764,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "lrG9AduNY47g"
   },
   "outputs": [],
   "source": [
    "# normalize/scale the data by dividing by the length of the character list.\n",
    "X = X / len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2807,
     "status": "ok",
     "timestamp": 1613538405764,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "bhvp9pN5_txN",
    "outputId": "52fbf777-410c-4631-9f36-b7cf535fd51e"
   },
   "outputs": [],
   "source": [
    "# Look at the first value of X\n",
    "#X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cqa6ZNx4AQwE"
   },
   "source": [
    "Even thought the values for the target variable are integers, they are essentially labels for the predicted characters. They are one-hot encoded using the to_categorical function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2794,
     "status": "ok",
     "timestamp": 1613538405765,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "XqS9wPlW_t5F",
    "outputId": "79c00f03-9da9-4588-a73b-a36dad43f0b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y_numeric_list)\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lb1V-QYZFdoe"
   },
   "source": [
    "---\n",
    "### Load LSTM Model\n",
    "In this notebook, load a model that was previously trained and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "executionInfo": {
     "elapsed": 2785,
     "status": "ok",
     "timestamp": 1613538405765,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "R1tBdmEw_t-b"
   },
   "outputs": [],
   "source": [
    "# Save the model to my Google Drive so I can load it later from another notebook\n",
    "# model = load_model(f'/content/drive/MyDrive/ted/models/ted_model_{tag_name}')\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tTuw8KwXoh7"
   },
   "source": [
    "If a model failed during fitting, we can still load it's most recent weights which were stored in a checkpoint file.\n",
    "\n",
    "Use of ModelCheckPoint to save the model's progress example as described in the [TensorFlow documentation.](https://www.tensorflow.org/tutorials/keras/save_and_load#checkpoint_callback_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2773,
     "status": "ok",
     "timestamp": 1613538405765,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "fRahDlmOW9gK",
    "outputId": "aab19b18-9798-4c99-a3c8-71998b376e3a"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = f'{root_path}{corpus_file_name}/'\n",
    "\n",
    "latest = latest_checkpoint(checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Colab, model saved as \n",
    "# model.save(f'/content/drive/MyDrive/ted/models/ted_model_{tag_name}_seq_{sequence_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/models/ted_model_business\n"
     ]
    }
   ],
   "source": [
    "print ( f'{root_path}models/ted_model_{tag_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6235,
     "status": "ok",
     "timestamp": 1613538409235,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "3TuIcmh9W_16",
    "outputId": "fc764c9f-8eec-4e66-f5c5-9d9c9532645f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 80, 100)           40800     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 80, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 66)                8514      \n",
      "=================================================================\n",
      "Total params: 166,562\n",
      "Trainable params: 166,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(1000, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(256))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "\n",
    "# # Load the previously saved weights\n",
    "# model.load_weights(latest)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam' , metrics = ['accuracy','Recall','Precision'])\n",
    "#model = load_model(f'{latest}')\n",
    "\n",
    "# Use if there was a successful save of a model\n",
    "\n",
    "\n",
    "#model = load_model(f'{root_path}models/ted_model_{tag_name}')\n",
    "model = load_model(f'{root_path}/models/ted_model_{tag_name}')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yg18vLEitH-5"
   },
   "source": [
    "X_numeric_list contains all of our 40 character sequences. Choose one for a seed for the text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6228,
     "status": "ok",
     "timestamp": 1613538409236,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "3zTBAJRh_uC3",
    "outputId": "d6a0b853-b399-4b7c-e898-0166e55fb84f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random start index for seed text: 9114 sequence.\n",
      "[61, 44, 51, 0, 40, 53, 43, 0, 40, 51, 58, 54, 0, 59, 47, 40, 59, 0, 57, 54, 51, 44, 0, 42, 47, 40, 53, 46, 44, 58, 0, 42, 40, 53, 0, 58, 47, 40, 55, 44, 0, 59, 47, 44, 0, 52, 48, 53, 43, 3, 0, 33, 54, 0, 62, 47, 40, 59, 0, 47, 40, 55, 55, 44, 53, 58, 0, 54, 50, 40, 64, 0, 64, 54, 60, 0, 59, 40, 50, 44]\n"
     ]
    }
   ],
   "source": [
    "seed_start = random.randint(0, len(corpus) - sequence_length)\n",
    "print(f'Random start index for seed text: {seed_start} sequence.')\n",
    "\n",
    "X_seeded = X_numeric_list[seed_start]\n",
    "print(X_seeded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vj_Nlck8FRl"
   },
   "source": [
    "Convert this back to text so we can see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6220,
     "status": "ok",
     "timestamp": 1613538409236,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "lnHGnP3O_uFB",
    "outputId": "e087a11d-97d8-4e5b-efb3-bd0038c269a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vel and also that role changes can shape the mind. So what happens okay you take'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_string = ''.join([indices_char[letter_code] for letter_code in X_seeded])\n",
    "seed_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvDwmnKi8KFC"
   },
   "source": [
    "To generate text, we need to change the input text into a 3D shape as we did the X input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6984,
     "status": "ok",
     "timestamp": 1613538410022,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "21d8U6qaAADc",
    "outputId": "da487977-5e85-4468-8be6-505eb1038510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A prediction's shape:(1, 66)\n",
      "Prediction:\n",
      "[[9.6023411e-01 3.6121673e-06 1.1453022e-15 1.5051023e-02 1.1256549e-15\n",
      "  2.2267809e-11 7.8010709e-11 6.0025139e-14 2.2914915e-16 1.9633632e-14\n",
      "  4.5014583e-14 2.5579229e-24 5.5918828e-15 1.9282237e-16 2.0589097e-03\n",
      "  3.4238010e-12 1.2886770e-13 2.0849728e-14 2.1221766e-11 1.6299131e-10\n",
      "  2.0263212e-10 7.1127099e-13 1.7985463e-13 1.9795242e-07 5.1315935e-16\n",
      "  3.1515199e-19 1.0535313e-11 8.4331681e-11 5.2911614e-14 4.0347048e-10\n",
      "  1.0707417e-13 2.4099792e-23 7.0585631e-15 2.6025366e-11 4.0938449e-13\n",
      "  3.2888788e-15 1.2451486e-10 1.2516598e-08 9.4741767e-12 9.0302020e-24\n",
      "  7.2955161e-05 1.2253222e-04 4.3681208e-05 1.7929057e-03 3.8078558e-04\n",
      "  7.9270467e-06 2.9920586e-05 1.3755137e-04 4.1783541e-03 3.1948221e-07\n",
      "  5.4178305e-05 3.2516857e-04 9.1172209e-05 3.8952224e-03 1.4868609e-04\n",
      "  1.7311604e-05 2.5032219e-07 6.8856077e-04 9.6915243e-03 1.2774025e-04\n",
      "  1.2002273e-04 3.6602105e-05 7.1815055e-05 1.7357801e-08 6.1677763e-04\n",
      "  1.3470685e-07]]\n"
     ]
    }
   ],
   "source": [
    "temp_x = np.reshape(X_seeded, (1, len(X_seeded) , 1))\n",
    "# normalize/scale the data by dividing by the length of the character list.\n",
    "temp_x = temp_x / len(chars)\n",
    "prediction = model.predict(temp_x, verbose=0)\n",
    "print(f\"A prediction's shape:{prediction.shape}\")\n",
    "print('Prediction:')\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dQEpt5uAJcE"
   },
   "source": [
    "Each prediction produces an result of shape (1, 75), and contains a predicted probability of a character. Use argmax to find the index of the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6977,
     "status": "ok",
     "timestamp": 1613538410022,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "7XoGksJ2AIoZ",
    "outputId": "a4ac631e-f9bb-4017-e96f-ed8a8ff4cf1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ax7a5bKoA3FJ"
   },
   "source": [
    "So the first letter predicted after the seed sequence is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6971,
     "status": "ok",
     "timestamp": 1613538410022,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "ErPPRZ-4AIt5",
    "outputId": "ab74b69d-bdd6-4d7d-fc12-a2ad04a99458"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6964,
     "status": "ok",
     "timestamp": 1613538410023,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "cLexXeVQAIza"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51684,
     "status": "ok",
     "timestamp": 1613538454748,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "BE7FR8en_uG3",
    "outputId": "073fe9fc-8225-4372-ccba-e26dda5ea2ff"
   },
   "outputs": [],
   "source": [
    "# Put all predicted characters in a list, then convert to a string later.\n",
    "complete_predicted_text =[]\n",
    "\n",
    "# Generate 1000 characters\n",
    "for i in range(600):\n",
    "    # reshape to 1 row, sequence length, and 1 for predicting one character as the target\n",
    "    temp_x = np.reshape(X_seeded, (1, len(X_seeded) , 1))\n",
    "    # normalize/scale the data by dividing by the length of the character list.\n",
    "    temp_x = temp_x / len(chars)\n",
    "    prediction = model.predict(temp_x, verbose=0)\n",
    "    complete_predicted_text.append(indices_char[np.argmax(prediction)])\n",
    "\n",
    "    # After predicting, add this character's numeric value on to the randomly\n",
    "    # chose seed string, and use this for another prediction\n",
    "    X_seeded.append(np.argmax(prediction))\n",
    "\n",
    "    # Move the seeded text up one character, so create a new sequence\n",
    "    X_seeded = X_seeded[1:len(X_seeded)]\n",
    "\n",
    "\n",
    "#print (complete_predicted_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "le8p2x7pP35N"
   },
   "source": [
    "The predicted results are a list of characters, so convert into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51677,
     "status": "ok",
     "timestamp": 1613538454748,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "F9xdtOGE_-8p",
    "outputId": "d825a21f-5e66-478e-eb9b-beb7b3bd58ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vel and also that role changes can shape the mind. So what happens okay you take-> the powerful  So the second the same',\n",
       " 'things to the pert of the boimg the bright bround the mand of the canele thiy wene people  Its a compurer comfinent',\n",
       " 'They have the sert of the boise the tame things they wene people  They have the sereered  The seaond the same things',\n",
       " 'they wene people  They have the sereered  The seaond the same things they wene people  They have the sereered  The',\n",
       " 'seaond the same things they wene people  They have the sereered  The seaond the same things they wene people  They have',\n",
       " 'the sereered  The seaond the same things they wene people  They have the sereered  The seaond']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_string = ''.join(complete_predicted_text)\n",
    "\n",
    "# Wrap to 120 characters just so I can visually compare to the original string.\n",
    "textwrap.wrap(seed_string + '->'+ predicted_string, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51672,
     "status": "ok",
     "timestamp": 1613538454749,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "QsIg_Zg8U487",
    "outputId": "740e0b8c-5879-48d4-b85d-975b3d316626"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vel and also that role changes can shape the mind. So what happens okay you take a role change what happens if you do',\n",
       " 'that at a really minimal level like this tiny manipulation this tiny intervention? For two minutes you say I want you to',\n",
       " 'stand like this and its going to make you feel more powerful. So this is what we did. We decided to bring people into',\n",
       " 'the lab and run a little experiment and these people adopted for two minutes either highpower poses or lowpower poses',\n",
       " 'and Im just going to show you five of the poses although they took on only two. So heres one. A couple more. This one',\n",
       " 'has been dubbed the Wonder Woman by the media. Here are a couple more. So you can be standing or you can be sitting. And',\n",
       " 'here are the lowpower poses. So youre folding up youre making yourself small. This one is very lowpower. When youre',\n",
       " 'touching your neck youre really protecting yourself. So this is what happens. They come in they spit into a vial for two',\n",
       " 'minutes we say You need to do this or this. They dont look at pictures of the poses. We dont want to prime them with a',\n",
       " 'concept of power. We want them to be feeling power. So two minutes they do this. We then ask them How powerful do you',\n",
       " 'feel? on a series of items and then we give them an opportunity to gamble and then we take another saliva sample. Thats',\n",
       " 'it. Thats the whole experiment. So this is what we find. Risk tolerance which is the gambling we find that when you are',\n",
       " 'in the highpower pose condition 86 percent of you will gamble. When youre in the lowpower pose condition only 60 percent',\n",
       " 'and thats a whopping significant difference. Heres what we find on testosterone. From their baseline when they come in',\n",
       " 'highpower people experience about a 20percent increase and lowpower people experience about a 10percent decrease. So',\n",
       " 'again two minutes and you get these changes. Heres what you get on cortisol. Highpower people experience about a',\n",
       " '25percent decrease and the lowpower people experience about a 15percent increase. So two minutes lead']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the original seed string to see what came after it\n",
    "original_paragraph = corpus[corpus.find(seed_string): corpus.find(seed_string) + 2000]\n",
    "\n",
    "textwrap.wrap(original_paragraph, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51666,
     "status": "ok",
     "timestamp": 1613538454749,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "MSWX94UK8WhN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51661,
     "status": "ok",
     "timestamp": 1613538454749,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "0MKrmY6C8VFL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51657,
     "status": "ok",
     "timestamp": 1613538454750,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "HNC6Lxt__9N-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51652,
     "status": "ok",
     "timestamp": 1613538454750,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "SiYaK6B_AHZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNa5+T0gWfZd3GC6w1ulZ0Z",
   "collapsed_sections": [],
   "name": "Ted Talk Load Model and Predict",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
