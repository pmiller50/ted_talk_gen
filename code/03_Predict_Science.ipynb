{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8VMnuH-l2o_"
   },
   "source": [
    "TED talk text generator\n",
    "\n",
    "Generate using a character based model.\n",
    "\n",
    "The code is this notebook is a partial modification of several tutorials, blog posts and YouTube videos. The main sources include:\n",
    "* [Text Generation With LSTM Recurrent Neural Networks in Python with Keras](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/) by Dr. Jason Brownlee\n",
    "* [Text Generation with Python and TensorFlow/Keras](https://stackabuse.com/text-generation-with-python-and-tensorflow-keras/) by Dan Nelson\n",
    "* YouTube: [167 - Text prediction using LSTM (English text)](https://youtu.be/zyCpntcVKSo?t=2) by Sreenivas B.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1613538403438,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "OLpQP9ZPs3Z8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.train import latest_checkpoint\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "import random\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1613538403660,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "waLxIXEXmCoW",
    "outputId": "c9837e2d-5c4e-489f-9030-e6c18a9bcd1a"
   },
   "outputs": [],
   "source": [
    "# Attach to my Google drive so I can save the csv file later\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1613538403660,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "1ygYMqkOddlx"
   },
   "outputs": [],
   "source": [
    "#tag_name = 'all_transcripts'\n",
    "#tag_name = 'brain'\n",
    "#tag_name = 'business'\n",
    "#tag_name = 'creativity'\n",
    "#tag_name = 'culture'\n",
    "#tag_name = 'psychology'\n",
    "tag_name = 'science'\n",
    "\n",
    "lower_corpus = False\n",
    "\n",
    "if lower_corpus:\n",
    "    corpus_file_name = tag_name + '_lowercase'\n",
    "else:\n",
    "    corpus_file_name = tag_name + '_sentence_case'\n",
    "\n",
    "# This switch makes it easier running locally or in a Google Colab environment\n",
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    root_path = '/content/drive/MyDrive/ted/'\n",
    "else:\n",
    "    root_path = '../data/'\n",
    "    \n",
    "sequence_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 863,
     "status": "ok",
     "timestamp": 1613538403661,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "V1ljkpt0l1kx"
   },
   "outputs": [],
   "source": [
    "with open(f'{root_path}{corpus_file_name}.txt', encoding='utf-8') as f:\n",
    "    corpus = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 1322,
     "status": "ok",
     "timestamp": 1613538404130,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "K8pyPFcnmCD9",
    "outputId": "3813cc1e-6871-4766-9709-f5e11b5f7660"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So I want to start by offering you a free no-tech life hack, and all it requires of you is  that you change your posture for two minutes. But before I give it away, I want to ask you to right now do a little audit of your body and what you're doing with your body. So how many of you are sort of making yourselves smaller? Maybe you're hunching, crossing your legs, maybe wrapping your ankles. Sometimes we hold onto our arms like this. Sometimes we spread out.  I see you. So I want you to pay atten\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDIMVXs-kwz3"
   },
   "source": [
    "The code below is used in almost every article I have seen about LSTM for text generation, but this snippet is adapted from :\n",
    "https://www.kaggle.com/mrisdal/intro-to-lstms-w-keras-gpu-for-text-generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chars = sorted(list(set(corpus)))\n",
    "\n",
    "#remove most punctuation, but leave spaces, exclamation points, and periods\n",
    "list_to_remove = ['\"', '&', '-', ',', \"'\", '/', ';',  'â€”']\n",
    "\n",
    "chars = [character for character in all_chars if character not in list_to_remove]\n",
    "# print(chars)\n",
    "# # hat tip to this post for the idea of removing one list from another\n",
    "# # https://www.geeksforgeeks.org/python-remove-all-values-from-a-list-present-in-other-list/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all unwanted characters from the original corpus\n",
    "corpus_list = [character for character in corpus if character not in list_to_remove]\n",
    "\n",
    "# Re-join all letters back into a single string as the updated corpus\n",
    "corpus = ''.join(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1313,
     "status": "ok",
     "timestamp": 1613538404131,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "KW8k2n7piPca",
    "outputId": "70c7cd09-9650-4e03-8fb5-561532a8aeed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in the corpus: 68\n"
     ]
    }
   ],
   "source": [
    "# If running models with punctuation removed, leave commented out\n",
    "# chars = sorted(list(set(corpus)))\n",
    "\n",
    "print('Number of unique characters in the corpus:', len(chars))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1304,
     "status": "ok",
     "timestamp": 1613538404131,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "vwPryvRueRtT",
    "outputId": "a90beecb-f0fc-48ef-e803-c04afc88d5ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '%': 2, '.': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, '?': 14, 'A': 15, 'B': 16, 'C': 17, 'D': 18, 'E': 19, 'F': 20, 'G': 21, 'H': 22, 'I': 23, 'J': 24, 'K': 25, 'L': 26, 'M': 27, 'N': 28, 'O': 29, 'P': 30, 'Q': 31, 'R': 32, 'S': 33, 'T': 34, 'U': 35, 'V': 36, 'W': 37, 'X': 38, 'Y': 39, '[': 40, ']': 41, 'a': 42, 'b': 43, 'c': 44, 'd': 45, 'e': 46, 'f': 47, 'g': 48, 'h': 49, 'i': 50, 'j': 51, 'k': 52, 'l': 53, 'm': 54, 'n': 55, 'o': 56, 'p': 57, 'q': 58, 'r': 59, 's': 60, 't': 61, 'u': 62, 'v': 63, 'w': 64, 'x': 65, 'y': 66, 'z': 67}\n"
     ]
    }
   ],
   "source": [
    "# Show character to index mapping\n",
    "print (char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1294,
     "status": "ok",
     "timestamp": 1613538404132,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "RqMa6shPiQrd",
    "outputId": "6965acf5-10cf-4624-efde-abb4f61eeb4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: '!', 2: '%', 3: '.', 4: '0', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: '?', 15: 'A', 16: 'B', 17: 'C', 18: 'D', 19: 'E', 20: 'F', 21: 'G', 22: 'H', 23: 'I', 24: 'J', 25: 'K', 26: 'L', 27: 'M', 28: 'N', 29: 'O', 30: 'P', 31: 'Q', 32: 'R', 33: 'S', 34: 'T', 35: 'U', 36: 'V', 37: 'W', 38: 'X', 39: 'Y', 40: '[', 41: ']', 42: 'a', 43: 'b', 44: 'c', 45: 'd', 46: 'e', 47: 'f', 48: 'g', 49: 'h', 50: 'i', 51: 'j', 52: 'k', 53: 'l', 54: 'm', 55: 'n', 56: 'o', 57: 'p', 58: 'q', 59: 'r', 60: 's', 61: 't', 62: 'u', 63: 'v', 64: 'w', 65: 'x', 66: 'y', 67: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# Show index to character mapping\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1286,
     "status": "ok",
     "timestamp": 1613538404132,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "ns5RcDesiQzZ",
    "outputId": "fc7676a5-4d17-4b11-e18c-929b51c72f50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input corpus contains 78,510 characters.\n"
     ]
    }
   ],
   "source": [
    "print (f'The input corpus contains {len(corpus):,} characters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1278,
     "status": "ok",
     "timestamp": 1613538404132,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "85NHcjWuiQ7D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXgbFM-46jrS"
   },
   "source": [
    "The model will use arbitrary length of characters, e.g. 40, and then predict the next character that will appear (the 41st).\n",
    "\n",
    "I would like to change this sequence length in different models, to see how it might affect the model's performance.\n",
    "\n",
    "Larger might be better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1613538404133,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "CgLONw9RiRC-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNWrhS2LJkOt"
   },
   "source": [
    "Loop through the corpus, creating segments of 40 characters, plus a segment of a single character that would appear after it. These segments are then converted into their respective digits, and loaded into X\n",
    "\n",
    "In addition, create a list of target values. The target, y, is a single text character, and is also converted into a corresponding numeric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1265,
     "status": "ok",
     "timestamp": 1613538404133,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "uPWsaG39Si52",
    "outputId": "ec027126-9d6e-4bb4-cd0d-965a7c65f1ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So I want to start by offering you a free notech l'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1613538404133,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "pB06ivEKOa2f",
    "outputId": "7f8f681f-b956-4c94-a8d1-fed28e011bd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o I want to start by offering you a free'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1248,
     "status": "ok",
     "timestamp": 1613538404134,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "QN8H5lmRPzV8",
    "outputId": "ebd703f3-9fd8-4a71-f00a-791ff00b8ceb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 2091,
     "status": "ok",
     "timestamp": 1613538404984,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "z4bwf70jiRIF"
   },
   "outputs": [],
   "source": [
    "# For future modeling, we could try to offset the sequences by more than one\n",
    "# letter. For now the model will look at every sequence right after another.\n",
    "step = 1\n",
    "\n",
    "X_numeric_list = []\n",
    "y_numeric_list = []\n",
    "\n",
    "\n",
    "for i in range (0, len(corpus) - sequence_length, step):\n",
    "    # To find X when still as characters, loop through and extract\n",
    "    # a sequence for example, from the 2nd to the 42nd, as in corpus[1:41] since \n",
    "    # the string index is zero-based\n",
    "    X_char_sequence = corpus[i:i + sequence_length]  #exclusive\n",
    "    y_char = corpus[i + sequence_length]\n",
    "\n",
    "    # Convert the X character sequence into a list of integers, using the \n",
    "    # dictionary created above.\n",
    "    X_numeric_list.append( [char_indices[letter] for letter in X_char_sequence])\n",
    "    # Also convert target letter y to it's corresponding numeric value in the\n",
    "    # dictionary\n",
    "    y_numeric_list.append(char_indices[y_char])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2085,
     "status": "ok",
     "timestamp": 1613538404984,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "OAIoz7XIXIWV",
    "outputId": "1368effc-745f-4a2a-df82-09c0a57e1d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 56, 0, 23, 0, 64, 42, 55, 61, 0, 61, 56, 0, 60, 61, 42, 59, 61, 0, 43, 66, 0, 56, 47, 47, 46, 59, 50, 55, 48, 0, 66, 56, 62, 0, 42, 0, 47, 59, 46, 46, 0, 55, 56, 61, 46, 44, 49, 0, 53]\n",
      "[56, 0, 23, 0, 64, 42, 55, 61, 0, 61, 56, 0, 60, 61, 42, 59, 61, 0, 43, 66, 0, 56, 47, 47, 46, 59, 50, 55, 48, 0, 66, 56, 62, 0, 42, 0, 47, 59, 46, 46, 0, 55, 56, 61, 46, 44, 49, 0, 53, 50]\n"
     ]
    }
   ],
   "source": [
    "# Look at the first two converted sequences\n",
    "print ( X_numeric_list[0])\n",
    "print ( X_numeric_list[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2078,
     "status": "ok",
     "timestamp": 1613538404985,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "W_WYfvRUXLd8",
    "outputId": "41af6ff4-894e-4a89-b1e1-2439439852cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 47]\n"
     ]
    }
   ],
   "source": [
    "print ( y_numeric_list[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2071,
     "status": "ok",
     "timestamp": 1613538404985,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "pUBI2jozXYT1",
    "outputId": "5b950e77-26a9-45a7-d5df-a218ee01509e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'j'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2064,
     "status": "ok",
     "timestamp": 1613538404986,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "PhR81VtiXzyJ",
    "outputId": "ce15680c-aa72-4aee-9e48-230cfa3acddc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So I want to start by offering you a free n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:43]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2X_QDPSqYAmR"
   },
   "source": [
    "This example is a little hard to follow, since we happened to be in the middle of the word 'been'. The letter e is mapped to 51.\n",
    "\n",
    "However the beginning of the sequence has been shifted by one as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2054,
     "status": "ok",
     "timestamp": 1613538404986,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "nkX8BKMMX4hh",
    "outputId": "7ff2f80c-cfd3-432f-b2ac-fbbf18042b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 78,460 entries in X_numeric_list\n"
     ]
    }
   ],
   "source": [
    "print (f'There are {len(X_numeric_list):,} entries in X_numeric_list') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tn3uKqnJasUf"
   },
   "source": [
    "An LSTM model needs the X data to be in 3 dimensions:\n",
    "* Samples (number of rows)\n",
    "* Time steps (this implies time series. In this example this corresponds to the sequence_length)\n",
    "* Features (the target, or y variable)\n",
    "\n",
    "This [blog post by Dr. John Brownlee](https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/) contains a longer explanation, which I paraphrased here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 2825,
     "status": "ok",
     "timestamp": 1613538405763,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "qH7OG0kAYALM"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "# Samples is the total number of 40 character text fragments created above\n",
    "# Time step is the sequence length, which is this case is 40, but might change\n",
    "# in other model variations\n",
    "# Feature is one, since the model is predicting one character at a time\n",
    "X = np.reshape(X_numeric_list, (len(X_numeric_list), sequence_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2819,
     "status": "ok",
     "timestamp": 1613538405763,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "WYTRXPhbarU0",
    "outputId": "3263bee5-a669-47b5-b02a-9f03e452b4cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78460, 50, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 2813,
     "status": "ok",
     "timestamp": 1613538405764,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "lrG9AduNY47g"
   },
   "outputs": [],
   "source": [
    "# normalize/scale the data by dividing by the length of the character list.\n",
    "X = X / len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2807,
     "status": "ok",
     "timestamp": 1613538405764,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "bhvp9pN5_txN",
    "outputId": "52fbf777-410c-4631-9f36-b7cf535fd51e"
   },
   "outputs": [],
   "source": [
    "# Look at the first value of X\n",
    "#X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cqa6ZNx4AQwE"
   },
   "source": [
    "Even thought the values for the target variable are integers, they are essentially labels for the predicted characters. They are one-hot encoded using the to_categorical function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2794,
     "status": "ok",
     "timestamp": 1613538405765,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "XqS9wPlW_t5F",
    "outputId": "79c00f03-9da9-4588-a73b-a36dad43f0b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y_numeric_list)\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lb1V-QYZFdoe"
   },
   "source": [
    "---\n",
    "### Load LSTM Model\n",
    "In this notebook, load a model that was previously trained and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 2785,
     "status": "ok",
     "timestamp": 1613538405765,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "R1tBdmEw_t-b"
   },
   "outputs": [],
   "source": [
    "# Save the model to my Google Drive so I can load it later from another notebook\n",
    "# model = load_model(f'/content/drive/MyDrive/ted/models/ted_model_{tag_name}')\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tTuw8KwXoh7"
   },
   "source": [
    "If a model failed during fitting, we can still load it's most recent weights which were stored in a checkpoint file.\n",
    "\n",
    "Use of ModelCheckPoint to save the model's progress example as described in the [TensorFlow documentation.](https://www.tensorflow.org/tutorials/keras/save_and_load#checkpoint_callback_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2773,
     "status": "ok",
     "timestamp": 1613538405765,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "fRahDlmOW9gK",
    "outputId": "aab19b18-9798-4c99-a3c8-71998b376e3a"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = f'{root_path}{corpus_file_name}/'\n",
    "\n",
    "latest = latest_checkpoint(checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Colab, model saved as \n",
    "# model.save(f'/content/drive/MyDrive/ted/models/ted_model_{tag_name}_seq_{sequence_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/models/ted_model_science\n"
     ]
    }
   ],
   "source": [
    "print ( f'{root_path}models/ted_model_{tag_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6235,
     "status": "ok",
     "timestamp": 1613538409235,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "3TuIcmh9W_16",
    "outputId": "fc764c9f-8eec-4e66-f5c5-9d9c9532645f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 50, 1000)          4008000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50, 1000)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 256)               1287168   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 68)                17476     \n",
      "=================================================================\n",
      "Total params: 5,312,644\n",
      "Trainable params: 5,312,644\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(1000, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(256))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "\n",
    "# # Load the previously saved weights\n",
    "# model.load_weights(latest)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam' , metrics = ['accuracy','Recall','Precision'])\n",
    "#model = load_model(f'{latest}')\n",
    "\n",
    "# Use if there was a successful save of a model\n",
    "\n",
    "\n",
    "#model = load_model(f'{root_path}models/ted_model_{tag_name}')\n",
    "model = load_model(f'{root_path}/models/ted_model_{tag_name}')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yg18vLEitH-5"
   },
   "source": [
    "X_numeric_list contains all of our 40 character sequences. Choose one for a seed for the text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6228,
     "status": "ok",
     "timestamp": 1613538409236,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "3zTBAJRh_uC3",
    "outputId": "d6a0b853-b399-4b7c-e898-0166e55fb84f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random start index for seed text: 8050 sequence.\n",
      "[46, 59, 46, 55, 44, 46, 60, 0, 56, 55, 0, 61, 64, 56, 0, 52, 46, 66, 0, 0, 61, 46, 60, 61, 56, 60, 61, 46, 59, 56, 55, 46, 0, 64, 49, 50, 44, 49, 0, 50, 60, 0, 61, 49, 46, 0, 45, 56, 54, 50]\n"
     ]
    }
   ],
   "source": [
    "seed_start = random.randint(0, len(corpus) - sequence_length)\n",
    "print(f'Random start index for seed text: {seed_start} sequence.')\n",
    "\n",
    "X_seeded = X_numeric_list[seed_start]\n",
    "print(X_seeded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vj_Nlck8FRl"
   },
   "source": [
    "Convert this back to text so we can see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6220,
     "status": "ok",
     "timestamp": 1613538409236,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "lnHGnP3O_uFB",
    "outputId": "e087a11d-97d8-4e5b-efb3-bd0038c269a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'erences on two key  testosterone which is the domi'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_string = ''.join([indices_char[letter_code] for letter_code in X_seeded])\n",
    "seed_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvDwmnKi8KFC"
   },
   "source": [
    "To generate text, we need to change the input text into a 3D shape as we did the X input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6984,
     "status": "ok",
     "timestamp": 1613538410022,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "21d8U6qaAADc",
    "outputId": "da487977-5e85-4468-8be6-505eb1038510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A prediction's shape:(1, 68)\n",
      "Prediction:\n",
      "[[9.01670865e-06 1.67315932e-07 7.84596243e-16 1.63557644e-07\n",
      "  2.35479686e-16 3.51622342e-11 3.95659796e-13 3.46711380e-15\n",
      "  3.55786228e-14 4.32721052e-13 3.03968448e-11 6.13680417e-12\n",
      "  1.44444292e-11 4.72688837e-14 1.07734891e-07 1.12283681e-11\n",
      "  8.71870528e-14 1.75224622e-14 1.06849328e-12 8.93032610e-12\n",
      "  2.57501043e-09 4.03863087e-13 6.57680697e-14 2.65548954e-12\n",
      "  3.69645183e-11 1.20949792e-10 4.56405096e-13 1.45210358e-10\n",
      "  6.96408399e-14 5.03313675e-11 1.32617929e-13 7.35243487e-15\n",
      "  7.35283882e-12 1.51552833e-11 3.72451072e-12 2.88187443e-12\n",
      "  4.11755509e-13 2.21744689e-11 1.06282899e-15 2.25444576e-12\n",
      "  2.45700104e-18 9.86975224e-11 2.75793311e-04 1.67417238e-04\n",
      "  7.56032299e-03 6.77888820e-05 2.39993708e-04 7.03381229e-05\n",
      "  4.10826993e-04 1.38482192e-05 6.16201123e-06 2.06102141e-06\n",
      "  1.00086289e-07 5.96936559e-04 4.13715388e-05 9.89724994e-01\n",
      "  9.48044544e-06 9.31184695e-05 2.87266062e-06 1.06017405e-05\n",
      "  4.17593197e-04 8.96501952e-05 1.53439163e-04 2.34042864e-06\n",
      "  1.05710787e-05 3.40909395e-07 1.07537858e-06 2.15141172e-05]]\n"
     ]
    }
   ],
   "source": [
    "temp_x = np.reshape(X_seeded, (1, len(X_seeded) , 1))\n",
    "# normalize/scale the data by dividing by the length of the character list.\n",
    "temp_x = temp_x / len(chars)\n",
    "prediction = model.predict(temp_x, verbose=0)\n",
    "print(f\"A prediction's shape:{prediction.shape}\")\n",
    "print('Prediction:')\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dQEpt5uAJcE"
   },
   "source": [
    "Each prediction produces an result of shape (1, 75), and contains a predicted probability of a character. Use argmax to find the index of the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6977,
     "status": "ok",
     "timestamp": 1613538410022,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "7XoGksJ2AIoZ",
    "outputId": "a4ac631e-f9bb-4017-e96f-ed8a8ff4cf1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ax7a5bKoA3FJ"
   },
   "source": [
    "So the first letter predicted after the seed sequence is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6971,
     "status": "ok",
     "timestamp": 1613538410022,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "ErPPRZ-4AIt5",
    "outputId": "ab74b69d-bdd6-4d7d-fc12-a2ad04a99458"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6964,
     "status": "ok",
     "timestamp": 1613538410023,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "cLexXeVQAIza"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51684,
     "status": "ok",
     "timestamp": 1613538454748,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "BE7FR8en_uG3",
    "outputId": "073fe9fc-8225-4372-ccba-e26dda5ea2ff"
   },
   "outputs": [],
   "source": [
    "# Put all predicted characters in a list, then convert to a string later.\n",
    "complete_predicted_text =[]\n",
    "\n",
    "# Generate 1000 characters\n",
    "for i in range(600):\n",
    "    # reshape to 1 row, sequence length, and 1 for predicting one character as the target\n",
    "    temp_x = np.reshape(X_seeded, (1, len(X_seeded) , 1))\n",
    "    # normalize/scale the data by dividing by the length of the character list.\n",
    "    temp_x = temp_x / len(chars)\n",
    "    prediction = model.predict(temp_x, verbose=0)\n",
    "    complete_predicted_text.append(indices_char[np.argmax(prediction)])\n",
    "\n",
    "    # After predicting, add this character's numeric value on to the randomly\n",
    "    # chose seed string, and use this for another prediction\n",
    "    X_seeded.append(np.argmax(prediction))\n",
    "\n",
    "    # Move the seeded text up one character, so create a new sequence\n",
    "    X_seeded = X_seeded[1:len(X_seeded)]\n",
    "\n",
    "\n",
    "#print (complete_predicted_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "le8p2x7pP35N"
   },
   "source": [
    "The predicted results are a list of characters, so convert into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51677,
     "status": "ok",
     "timestamp": 1613538454748,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "F9xdtOGE_-8p",
    "outputId": "d825a21f-5e66-478e-eb9b-beb7b3bd58ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['erences on two key  testosterone which is the domi->nance hormone and sorted mn the byternal world. So what we tand to',\n",
       " 'do in onre of the sout of eerice. Its woree ieed sooeont werk been stuty  So we though tuamected inow this widt they do',\n",
       " 'tpter when toue and they do it what they do it what you geel powerful  So I gott its not possible. Than you dan be',\n",
       " 'sialking to do in the sersone besuer wese been tale aaautaclly donlaated in and of them  Then you went on your',\n",
       " 'bodin.anonhgtie youre martioy. So this is what were toot of souer upenis silet? And I lave aboogs the pie have',\n",
       " 'interisted  I dont maa ang mystefies byeepinns ard alled tiat when toent hav']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_string = ''.join(complete_predicted_text)\n",
    "\n",
    "# Wrap to 120 characters just so I can visually compare to the original string.\n",
    "textwrap.wrap(seed_string + '->'+ predicted_string, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51672,
     "status": "ok",
     "timestamp": 1613538454749,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "QsIg_Zg8U487",
    "outputId": "740e0b8c-5879-48d4-b85d-975b3d316626"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['erences on two key  testosterone which is the dominance hormone and cortisol which is the stress hormone. So what we',\n",
       " 'find is that highpower alpha males in primate hierarchies have high testosterone and low cortisol and powerful and',\n",
       " 'effective leaders also have high testosterone and low cortisol. So what does that mean? When you think about power',\n",
       " 'people tended to think only about testosterone because that was about dominance. But really power is also about how you',\n",
       " 'react to stress. So do you want the highpower leader thats dominant high on testosterone but really stress reactive?',\n",
       " 'Probably not right? You want the person whos powerful and assertive and dominant but not very stress reactive the person',\n",
       " 'whos laid back. So we know that in primate hierarchies if an alpha needs to take over if an individual needs to take',\n",
       " 'over an alpha role sort of suddenly within a few days that individuals testosterone has gone up significantly and his',\n",
       " 'cortisol has dropped significantly. So we have this evidence both that the body can shape the mind at least at the',\n",
       " 'facial level and also that role changes can shape the mind. So what happens okay you take a role change what happens if',\n",
       " 'you do that at a really minimal level like this tiny manipulation this tiny intervention? For two minutes you say I want',\n",
       " 'you to stand like this and its going to make you feel more powerful. So this is what we did. We decided to bring people',\n",
       " 'into the lab and run a little experiment and these people adopted for two minutes either highpower poses or lowpower',\n",
       " 'poses and Im just going to show you five of the poses although they took on only two. So heres one. A couple more. This',\n",
       " 'one has been dubbed the Wonder Woman by the media. Here are a couple more. So you can be standing or you can be sitting.',\n",
       " 'And here are the lowpower poses. So youre folding up youre making yourself small. This one is very lowpower. When youre',\n",
       " 'touching your neck youre really protecting yourself. So this is what happens. They come in they spit into']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the original seed string to see what came after it\n",
    "original_paragraph = corpus[corpus.find(seed_string): corpus.find(seed_string) + 2000]\n",
    "\n",
    "textwrap.wrap(original_paragraph, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51666,
     "status": "ok",
     "timestamp": 1613538454749,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "MSWX94UK8WhN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51661,
     "status": "ok",
     "timestamp": 1613538454749,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "0MKrmY6C8VFL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51657,
     "status": "ok",
     "timestamp": 1613538454750,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "HNC6Lxt__9N-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51652,
     "status": "ok",
     "timestamp": 1613538454750,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "SiYaK6B_AHZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNa5+T0gWfZd3GC6w1ulZ0Z",
   "collapsed_sections": [],
   "name": "Ted Talk Load Model and Predict",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
