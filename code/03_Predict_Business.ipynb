{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8VMnuH-l2o_"
   },
   "source": [
    "TED talk text generator\n",
    "\n",
    "Generate using a character based model.\n",
    "\n",
    "The code is this notebook is a partial modification of several tutorials, blog posts and YouTube videos. The main sources include:\n",
    "* [Text Generation With LSTM Recurrent Neural Networks in Python with Keras](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/) by Dr. Jason Brownlee\n",
    "* [Text Generation with Python and TensorFlow/Keras](https://stackabuse.com/text-generation-with-python-and-tensorflow-keras/) by Dan Nelson\n",
    "* YouTube: [167 - Text prediction using LSTM (English text)](https://youtu.be/zyCpntcVKSo?t=2) by Sreenivas B.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1613538403438,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "OLpQP9ZPs3Z8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.train import latest_checkpoint\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "import random\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1613538403660,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "waLxIXEXmCoW",
    "outputId": "c9837e2d-5c4e-489f-9030-e6c18a9bcd1a"
   },
   "outputs": [],
   "source": [
    "# Attach to my Google drive so I can save the csv file later\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1613538403660,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "1ygYMqkOddlx"
   },
   "outputs": [],
   "source": [
    "#tag_name = 'all_transcripts'\n",
    "#tag_name = 'brain'\n",
    "tag_name = 'business'\n",
    "#tag_name = 'creativity'\n",
    "#tag_name = 'culture'\n",
    "#tag_name = 'psychology'\n",
    "#tag_name = 'science'\n",
    "\n",
    "lower_corpus = False\n",
    "\n",
    "if lower_corpus:\n",
    "    corpus_file_name = tag_name + '_lowercase'\n",
    "else:\n",
    "    corpus_file_name = tag_name + '_sentence_case'\n",
    "\n",
    "# This switch makes it easier running locally or in a Google Colab environment\n",
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    root_path = '/content/drive/MyDrive/ted/'\n",
    "else:\n",
    "    root_path = '../data/'\n",
    "    \n",
    "sequence_length = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "executionInfo": {
     "elapsed": 863,
     "status": "ok",
     "timestamp": 1613538403661,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "V1ljkpt0l1kx"
   },
   "outputs": [],
   "source": [
    "with open(f'{root_path}{corpus_file_name}.txt', encoding='utf-8') as f:\n",
    "    corpus = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 1322,
     "status": "ok",
     "timestamp": 1613538404130,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "K8pyPFcnmCD9",
    "outputId": "3813cc1e-6871-4766-9709-f5e11b5f7660"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So I want to start by offering you a free no-tech life hack, and all it requires of you is  that you change your posture for two minutes. But before I give it away, I want to ask you to right now do a little audit of your body and what you're doing with your body. So how many of you are sort of making yourselves smaller? Maybe you're hunching, crossing your legs, maybe wrapping your ankles. Sometimes we hold onto our arms like this. Sometimes we spread out.  I see you. So I want you to pay atten\""
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDIMVXs-kwz3"
   },
   "source": [
    "The code below is used in almost every article I have seen about LSTM for text generation, but this snippet is adapted from :\n",
    "https://www.kaggle.com/mrisdal/intro-to-lstms-w-keras-gpu-for-text-generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '%', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "all_chars = sorted(list(set(corpus)))\n",
    "\n",
    "#remove most punctuation, but leave spaces, exclamation points, and periods\n",
    "list_to_remove = ['\"', '&', '-', ',', \"'\", '/', ';',  '—']\n",
    "\n",
    "# This list was used on Google Cloud\n",
    "#list_to_remove = ['\"', '&', '-', ',', \"'\", '/', ';',  '—', '%','[', ']']\n",
    "\n",
    "chars = [character for character in all_chars if character not in list_to_remove]\n",
    "print(chars)\n",
    "# hat tip to this post for the idea of removing one list from another\n",
    "# https://www.geeksforgeeks.org/python-remove-all-values-from-a-list-present-in-other-list/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all unwanted characters from the original corpus\n",
    "corpus_list = [character for character in corpus if character not in list_to_remove]\n",
    "\n",
    "# Re-join all letters back into a single string as the updated corpus\n",
    "corpus = ''.join(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1313,
     "status": "ok",
     "timestamp": 1613538404131,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "KW8k2n7piPca",
    "outputId": "70c7cd09-9650-4e03-8fb5-561532a8aeed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in the corpus: 66\n"
     ]
    }
   ],
   "source": [
    "# If running models with punctuation removed, leave commented out\n",
    "#chars = sorted(list(set(corpus)))\n",
    "\n",
    "print('Number of unique characters in the corpus:', len(chars))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1304,
     "status": "ok",
     "timestamp": 1613538404131,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "vwPryvRueRtT",
    "outputId": "a90beecb-f0fc-48ef-e803-c04afc88d5ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '%': 2, '.': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, '?': 14, 'A': 15, 'B': 16, 'C': 17, 'D': 18, 'E': 19, 'F': 20, 'G': 21, 'H': 22, 'I': 23, 'J': 24, 'K': 25, 'L': 26, 'M': 27, 'N': 28, 'O': 29, 'P': 30, 'Q': 31, 'R': 32, 'S': 33, 'T': 34, 'U': 35, 'V': 36, 'W': 37, 'Y': 38, 'Z': 39, 'a': 40, 'b': 41, 'c': 42, 'd': 43, 'e': 44, 'f': 45, 'g': 46, 'h': 47, 'i': 48, 'j': 49, 'k': 50, 'l': 51, 'm': 52, 'n': 53, 'o': 54, 'p': 55, 'q': 56, 'r': 57, 's': 58, 't': 59, 'u': 60, 'v': 61, 'w': 62, 'x': 63, 'y': 64, 'z': 65}\n"
     ]
    }
   ],
   "source": [
    "# Show character to index mapping\n",
    "print (char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1294,
     "status": "ok",
     "timestamp": 1613538404132,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "RqMa6shPiQrd",
    "outputId": "6965acf5-10cf-4624-efde-abb4f61eeb4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: '!', 2: '%', 3: '.', 4: '0', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: '?', 15: 'A', 16: 'B', 17: 'C', 18: 'D', 19: 'E', 20: 'F', 21: 'G', 22: 'H', 23: 'I', 24: 'J', 25: 'K', 26: 'L', 27: 'M', 28: 'N', 29: 'O', 30: 'P', 31: 'Q', 32: 'R', 33: 'S', 34: 'T', 35: 'U', 36: 'V', 37: 'W', 38: 'Y', 39: 'Z', 40: 'a', 41: 'b', 42: 'c', 43: 'd', 44: 'e', 45: 'f', 46: 'g', 47: 'h', 48: 'i', 49: 'j', 50: 'k', 51: 'l', 52: 'm', 53: 'n', 54: 'o', 55: 'p', 56: 'q', 57: 'r', 58: 's', 59: 't', 60: 'u', 61: 'v', 62: 'w', 63: 'x', 64: 'y', 65: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# Show index to character mapping\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1286,
     "status": "ok",
     "timestamp": 1613538404132,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "ns5RcDesiQzZ",
    "outputId": "fc7676a5-4d17-4b11-e18c-929b51c72f50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input corpus contains 68,253 characters.\n"
     ]
    }
   ],
   "source": [
    "print (f'The input corpus contains {len(corpus):,} characters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1278,
     "status": "ok",
     "timestamp": 1613538404132,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "85NHcjWuiQ7D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXgbFM-46jrS"
   },
   "source": [
    "The model will use arbitrary length of characters, e.g. 40, and then predict the next character that will appear (the 41st).\n",
    "\n",
    "I would like to change this sequence length in different models, to see how it might affect the model's performance.\n",
    "\n",
    "Larger might be better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1613538404133,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "CgLONw9RiRC-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNWrhS2LJkOt"
   },
   "source": [
    "Loop through the corpus, creating segments of 40 characters, plus a segment of a single character that would appear after it. These segments are then converted into their respective digits, and loaded into X\n",
    "\n",
    "In addition, create a list of target values. The target, y, is a single text character, and is also converted into a corresponding numeric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1265,
     "status": "ok",
     "timestamp": 1613538404133,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "uPWsaG39Si52",
    "outputId": "ec027126-9d6e-4bb4-cd0d-965a7c65f1ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So I want to start by offering you a free notech l'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1613538404133,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "pB06ivEKOa2f",
    "outputId": "7f8f681f-b956-4c94-a8d1-fed28e011bd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o I want to start by offering you a free'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1248,
     "status": "ok",
     "timestamp": 1613538404134,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "QN8H5lmRPzV8",
    "outputId": "ebd703f3-9fd8-4a71-f00a-791ff00b8ceb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "executionInfo": {
     "elapsed": 2091,
     "status": "ok",
     "timestamp": 1613538404984,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "z4bwf70jiRIF"
   },
   "outputs": [],
   "source": [
    "# For future modeling, we could try to offset the sequences by more than one\n",
    "# letter. For now the model will look at every sequence right after another.\n",
    "step = 1\n",
    "\n",
    "X_numeric_list = []\n",
    "y_numeric_list = []\n",
    "\n",
    "\n",
    "for i in range (0, len(corpus) - sequence_length, step):\n",
    "    # To find X when still as characters, loop through and extract\n",
    "    # a sequence for example, from the 2nd to the 42nd, as in corpus[1:41] since \n",
    "    # the string index is zero-based\n",
    "    X_char_sequence = corpus[i:i + sequence_length]  #exclusive\n",
    "    y_char = corpus[i + sequence_length]\n",
    "\n",
    "    # Convert the X character sequence into a list of integers, using the \n",
    "    # dictionary created above.\n",
    "    X_numeric_list.append( [char_indices[letter] for letter in X_char_sequence])\n",
    "    # Also convert target letter y to it's corresponding numeric value in the\n",
    "    # dictionary\n",
    "    y_numeric_list.append(char_indices[y_char])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2085,
     "status": "ok",
     "timestamp": 1613538404984,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "OAIoz7XIXIWV",
    "outputId": "1368effc-745f-4a2a-df82-09c0a57e1d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 54, 0, 23, 0, 62, 40, 53, 59, 0, 59, 54, 0, 58, 59, 40, 57, 59, 0, 41, 64, 0, 54, 45, 45, 44, 57, 48, 53, 46, 0, 64, 54, 60, 0, 40, 0, 45, 57, 44, 44, 0, 53, 54, 59, 44, 42, 47, 0, 51, 48, 45, 44, 0, 47, 40, 42, 50, 0, 40, 53, 43, 0, 40, 51, 51, 0, 48, 59, 0, 57, 44, 56, 60, 48, 57, 44, 58, 0, 54]\n",
      "[54, 0, 23, 0, 62, 40, 53, 59, 0, 59, 54, 0, 58, 59, 40, 57, 59, 0, 41, 64, 0, 54, 45, 45, 44, 57, 48, 53, 46, 0, 64, 54, 60, 0, 40, 0, 45, 57, 44, 44, 0, 53, 54, 59, 44, 42, 47, 0, 51, 48, 45, 44, 0, 47, 40, 42, 50, 0, 40, 53, 43, 0, 40, 51, 51, 0, 48, 59, 0, 57, 44, 56, 60, 48, 57, 44, 58, 0, 54, 45]\n"
     ]
    }
   ],
   "source": [
    "# Look at the first two converted sequences\n",
    "print ( X_numeric_list[0])\n",
    "print ( X_numeric_list[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2078,
     "status": "ok",
     "timestamp": 1613538404985,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "W_WYfvRUXLd8",
    "outputId": "41af6ff4-894e-4a89-b1e1-2439439852cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45, 0]\n"
     ]
    }
   ],
   "source": [
    "print ( y_numeric_list[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2071,
     "status": "ok",
     "timestamp": 1613538404985,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "pUBI2jozXYT1",
    "outputId": "5b950e77-26a9-45a7-d5df-a218ee01509e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2064,
     "status": "ok",
     "timestamp": 1613538404986,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "PhR81VtiXzyJ",
    "outputId": "ce15680c-aa72-4aee-9e48-230cfa3acddc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So I want to start by offering you a free n'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:43]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2X_QDPSqYAmR"
   },
   "source": [
    "This example is a little hard to follow, since we happened to be in the middle of the word 'been'. The letter e is mapped to 51.\n",
    "\n",
    "However the beginning of the sequence has been shifted by one as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2054,
     "status": "ok",
     "timestamp": 1613538404986,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "nkX8BKMMX4hh",
    "outputId": "7ff2f80c-cfd3-432f-b2ac-fbbf18042b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 68,173 entries in X_numeric_list\n"
     ]
    }
   ],
   "source": [
    "print (f'There are {len(X_numeric_list):,} entries in X_numeric_list') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tn3uKqnJasUf"
   },
   "source": [
    "An LSTM model needs the X data to be in 3 dimensions:\n",
    "* Samples (number of rows)\n",
    "* Time steps (this implies time series. In this example this corresponds to the sequence_length)\n",
    "* Features (the target, or y variable)\n",
    "\n",
    "This [blog post by Dr. John Brownlee](https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/) contains a longer explanation, which I paraphrased here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "executionInfo": {
     "elapsed": 2825,
     "status": "ok",
     "timestamp": 1613538405763,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "qH7OG0kAYALM"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "# Samples is the total number of 40 character text fragments created above\n",
    "# Time step is the sequence length, which is this case is 40, but might change\n",
    "# in other model variations\n",
    "# Feature is one, since the model is predicting one character at a time\n",
    "X = np.reshape(X_numeric_list, (len(X_numeric_list), sequence_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2819,
     "status": "ok",
     "timestamp": 1613538405763,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "WYTRXPhbarU0",
    "outputId": "3263bee5-a669-47b5-b02a-9f03e452b4cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68173, 80, 1)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "executionInfo": {
     "elapsed": 2813,
     "status": "ok",
     "timestamp": 1613538405764,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "lrG9AduNY47g"
   },
   "outputs": [],
   "source": [
    "# normalize/scale the data by dividing by the length of the character list.\n",
    "X = X / len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2807,
     "status": "ok",
     "timestamp": 1613538405764,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "bhvp9pN5_txN",
    "outputId": "52fbf777-410c-4631-9f36-b7cf535fd51e"
   },
   "outputs": [],
   "source": [
    "# Look at the first value of X\n",
    "#X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cqa6ZNx4AQwE"
   },
   "source": [
    "Even thought the values for the target variable are integers, they are essentially labels for the predicted characters. They are one-hot encoded using the to_categorical function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2794,
     "status": "ok",
     "timestamp": 1613538405765,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "XqS9wPlW_t5F",
    "outputId": "79c00f03-9da9-4588-a73b-a36dad43f0b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y_numeric_list)\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lb1V-QYZFdoe"
   },
   "source": [
    "---\n",
    "### Load LSTM Model\n",
    "In this notebook, load a model that was previously trained and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "executionInfo": {
     "elapsed": 2785,
     "status": "ok",
     "timestamp": 1613538405765,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "R1tBdmEw_t-b"
   },
   "outputs": [],
   "source": [
    "# Save the model to my Google Drive so I can load it later from another notebook\n",
    "# model = load_model(f'/content/drive/MyDrive/ted/models/ted_model_{tag_name}')\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tTuw8KwXoh7"
   },
   "source": [
    "If a model failed during fitting, we can still load it's most recent weights which were stored in a checkpoint file.\n",
    "\n",
    "Use of ModelCheckPoint to save the model's progress example as described in the [TensorFlow documentation.](https://www.tensorflow.org/tutorials/keras/save_and_load#checkpoint_callback_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2773,
     "status": "ok",
     "timestamp": 1613538405765,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "fRahDlmOW9gK",
    "outputId": "aab19b18-9798-4c99-a3c8-71998b376e3a"
   },
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_dir = f'{root_path}{corpus_file_name}/'\n",
    "\n",
    "latest = latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6235,
     "status": "ok",
     "timestamp": 1613538409235,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "3TuIcmh9W_16",
    "outputId": "fc764c9f-8eec-4e66-f5c5-9d9c9532645f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 80, 100)           40800     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 80, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 66)                8514      \n",
      "=================================================================\n",
      "Total params: 166,562\n",
      "Trainable params: 166,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # define the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(1000, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(256))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "\n",
    "# # Load the previously saved weights\n",
    "# model.load_weights(latest)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam' , metrics = ['accuracy','Recall','Precision'])\n",
    "\n",
    "\n",
    "# #model = load_model(f'{latest}')\n",
    "\n",
    "model = load_model(f'{root_path}models/ted_model_{tag_name}')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yg18vLEitH-5"
   },
   "source": [
    "X_numeric_list contains all of our 40 character sequences. Choose one for a seed for the text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6228,
     "status": "ok",
     "timestamp": 1613538409236,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "3zTBAJRh_uC3",
    "outputId": "d6a0b853-b399-4b7c-e898-0166e55fb84f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random start index for seed text: 25522 sequence.\n",
      "[0, 40, 53, 43, 0, 59, 47, 44, 64, 0, 58, 40, 64, 0, 23, 0, 50, 53, 54, 62, 0, 62, 47, 40, 59, 0, 40, 51, 51, 0, 59, 47, 44, 0, 45, 40, 42, 59, 58, 0, 40, 53, 43, 0, 43, 44, 59, 40, 48, 51, 58, 0, 58, 40, 64, 0, 41, 60, 59, 0, 48, 59, 0, 49, 60, 58, 59, 0, 43, 54, 44, 58, 53, 59, 0, 45, 44, 44, 51, 0]\n"
     ]
    }
   ],
   "source": [
    "seed_start = random.randint(0, len(corpus) - sequence_length)\n",
    "print(f'Random start index for seed text: {seed_start} sequence.')\n",
    "\n",
    "X_seeded = X_numeric_list[seed_start]\n",
    "print(X_seeded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vj_Nlck8FRl"
   },
   "source": [
    "Convert this back to text so we can see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6220,
     "status": "ok",
     "timestamp": 1613538409236,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "lnHGnP3O_uFB",
    "outputId": "e087a11d-97d8-4e5b-efb3-bd0038c269a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' and they say I know what all the facts and details say but it just doesnt feel '"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_string = ''.join([indices_char[letter_code] for letter_code in X_seeded])\n",
    "seed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6212,
     "status": "ok",
     "timestamp": 1613538409237,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "nmSHu7KtBULP",
    "outputId": "858e7171-be72-46b9-94a1-3d06586e19d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and they say I know what all the facts and details say but it just doesnt feel \n",
      "and they say I know what all the facts and details say but it just doesnt feel r\n",
      "nd they say I know what all the facts and details say but it just doesnt feel ri\n",
      "d they say I know what all the facts and details say but it just doesnt feel rig\n",
      " they say I know what all the facts and details say but it just doesnt feel righ\n",
      "they say I know what all the facts and details say but it just doesnt feel right\n",
      "hey say I know what all the facts and details say but it just doesnt feel right.\n",
      "ey say I know what all the facts and details say but it just doesnt feel right. \n",
      "y say I know what all the facts and details say but it just doesnt feel right. W\n",
      " say I know what all the facts and details say but it just doesnt feel right. Wh\n",
      "say I know what all the facts and details say but it just doesnt feel right. Why\n",
      "ay I know what all the facts and details say but it just doesnt feel right. Why \n",
      "y I know what all the facts and details say but it just doesnt feel right. Why w\n",
      " I know what all the facts and details say but it just doesnt feel right. Why wo\n",
      "I know what all the facts and details say but it just doesnt feel right. Why wou\n"
     ]
    }
   ],
   "source": [
    "# We can also use the seed_start value to see a larger picture of the original text\n",
    "for j in range(seed_start, seed_start + 15):\n",
    "    seed_numeric = X_numeric_list[j]\n",
    "    print (''.join([indices_char[letter_code] for letter_code in seed_numeric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6205,
     "status": "ok",
     "timestamp": 1613538409237,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "XP-zzHQIBUIa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvDwmnKi8KFC"
   },
   "source": [
    "To generate text, we need to change the input text into a 3D shape as we did the X input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6984,
     "status": "ok",
     "timestamp": 1613538410022,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "21d8U6qaAADc",
    "outputId": "da487977-5e85-4468-8be6-505eb1038510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A prediction's shape:(1, 66)\n",
      "Prediction:\n",
      "[[6.55110627e-02 1.62380172e-08 7.22737958e-09 5.77428087e-04\n",
      "  3.83840126e-10 1.62955257e-06 1.10020301e-06 2.09936985e-07\n",
      "  2.93604649e-06 9.01272806e-11 2.84031721e-05 1.75949877e-09\n",
      "  2.94932079e-06 1.19458816e-08 9.66042171e-06 2.13307703e-05\n",
      "  1.38316284e-06 4.60607055e-07 1.26736068e-05 3.43669376e-06\n",
      "  4.42905957e-06 1.23729353e-06 5.93449067e-06 2.23665242e-03\n",
      "  9.44183626e-07 5.02198496e-08 2.15528871e-06 1.28024967e-05\n",
      "  9.77628588e-07 1.30920826e-05 9.21515584e-06 2.54471292e-15\n",
      "  1.88702518e-06 1.35022738e-05 9.31698160e-05 4.97378323e-06\n",
      "  2.24511632e-06 2.00584982e-05 2.56678106e-07 5.36696881e-13\n",
      "  1.00508988e-01 7.45230773e-03 3.87055762e-02 1.41594782e-02\n",
      "  1.89767852e-02 1.07249036e-01 2.46014888e-03 2.01047845e-02\n",
      "  1.03763886e-01 1.27687212e-03 4.55720024e-03 3.74643281e-02\n",
      "  3.34713198e-02 1.98576786e-02 5.16988821e-02 7.51172611e-03\n",
      "  3.54217686e-04 1.73141479e-01 6.50645494e-02 7.32492954e-02\n",
      "  8.24578665e-03 1.58806739e-03 3.35015059e-02 4.31507124e-06\n",
      "  6.86418312e-03 1.69363630e-04]]\n"
     ]
    }
   ],
   "source": [
    "temp_x = np.reshape(X_seeded, (1, len(X_seeded) , 1))\n",
    "# normalize/scale the data by dividing by the length of the character list.\n",
    "temp_x = temp_x / len(chars)\n",
    "prediction = model.predict(temp_x, verbose=0)\n",
    "print(f\"A prediction's shape:{prediction.shape}\")\n",
    "print('Prediction:')\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dQEpt5uAJcE"
   },
   "source": [
    "Each prediction produces an result of shape (1, 75), and contains a predicted probability of a character. Use argmax to find the index of the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6977,
     "status": "ok",
     "timestamp": 1613538410022,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "7XoGksJ2AIoZ",
    "outputId": "a4ac631e-f9bb-4017-e96f-ed8a8ff4cf1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ax7a5bKoA3FJ"
   },
   "source": [
    "So the first letter predicted after the seed sequence is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6971,
     "status": "ok",
     "timestamp": 1613538410022,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "ErPPRZ-4AIt5",
    "outputId": "ab74b69d-bdd6-4d7d-fc12-a2ad04a99458"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6964,
     "status": "ok",
     "timestamp": 1613538410023,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "cLexXeVQAIza"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51684,
     "status": "ok",
     "timestamp": 1613538454748,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "BE7FR8en_uG3",
    "outputId": "073fe9fc-8225-4372-ccba-e26dda5ea2ff"
   },
   "outputs": [],
   "source": [
    "# Put all predicted characters in a list, then convert to a string later.\n",
    "complete_predicted_text =[]\n",
    "\n",
    "# Generate 1000 characters\n",
    "for i in range(500):\n",
    "    # reshape to 1 row, sequence length, and 1 for predicting one character as the target\n",
    "    temp_x = np.reshape(X_seeded, (1, len(X_seeded) , 1))\n",
    "    # normalize/scale the data by dividing by the length of the character list.\n",
    "    temp_x = temp_x / len(chars)\n",
    "    prediction = model.predict(temp_x, verbose=0)\n",
    "    complete_predicted_text.append(indices_char[np.argmax(prediction)])\n",
    "\n",
    "    # After predicting, add this character's numeric value on to the randomly\n",
    "    # chose seed string, and use this for another prediction\n",
    "    X_seeded.append(np.argmax(prediction))\n",
    "\n",
    "    # Move the seeded text up one character, so create a new sequence\n",
    "    X_seeded = X_seeded[1:len(X_seeded)]\n",
    "\n",
    "\n",
    "#print (complete_predicted_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "le8p2x7pP35N"
   },
   "source": [
    "The predicted results are a list of characters, so convert into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51677,
     "status": "ok",
     "timestamp": 1613538454748,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "F9xdtOGE_-8p",
    "outputId": "d825a21f-5e66-478e-eb9b-beb7b3bd58ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' and they say I know what all the facts and details say but it just doesnt feel ->right  To the seion who seine in the',\n",
       " 'somelems what you deel  Shey dal so matters  And the seione what you deel  Shey dal so to me the same the pertln  And I',\n",
       " 'was the same the somet of the someles  And I want to to the pemple who shene a coopue of the somelems of the seme of the',\n",
       " 'sooes of the purcee  And the same thes and they went to be hev  So I want to to the pemple who shen to de ho the',\n",
       " 'purposer  Shey do the semeoee  Shey went to be heve  And the same the pomelc  So I want to to the pemple who']"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_string = ''.join(complete_predicted_text)\n",
    "\n",
    "# Wrap to 120 characters just so I can visually compare to the original string.\n",
    "textwrap.wrap(seed_string + '->'+ predicted_string, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51672,
     "status": "ok",
     "timestamp": 1613538454749,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "QsIg_Zg8U487",
    "outputId": "740e0b8c-5879-48d4-b85d-975b3d316626"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' and they say I know what all the facts and details say but it just doesnt feel right. Why would we use that verb it',\n",
       " 'doesnt feel right? Because the part of the brain that controls decisionmaking doesnt control language. The best we can',\n",
       " 'muster up is I dont know. It just doesnt feel right. Or sometimes you say youre leading with your heart or soul. I hate',\n",
       " 'to break it to you those arent other body parts controlling your behavior. Its all happening here in your limbic brain',\n",
       " 'the part of the brain that controls decisionmaking and not language. But if you dont know why you do what you do and',\n",
       " 'people respond to why you do what you do then how will you ever get people to vote for you or buy something from you or',\n",
       " 'more importantly be loyal and want to be a part of what it is that you do. The goal is not just to sell to people who',\n",
       " 'need what you have the goal is to sell to people who believe what you believe. The goal is not just to hire people who',\n",
       " 'need a job its to hire people who believe what you believe. I always say that you know if you hire people just because',\n",
       " 'they can do a job theyll work for your money but if they believe what you believe theyll work for you with blood and',\n",
       " 'sweat and tears. Nowhere else is there a better example than with the Wright brothers. Most people dont know about',\n",
       " 'Samuel Pierpont Langley. And back in the early 20th century the pursuit of powered man flight was like the dot com of',\n",
       " 'the day. Everybody was trying it. And Samuel Pierpont Langley had what we assume to be the recipe for success. Even now',\n",
       " 'you ask people Why did your product or why did your company fail? and people always give you the same permutation of the',\n",
       " 'same three  undercapitalized the wrong people bad market conditions. Its always the same three things so lets explore',\n",
       " 'that. Samuel Pierpont Langley was given 50000 dollars by the War Department to figure out this flying machine. Money was',\n",
       " 'no problem. He held a seat at Harvard and worked at the Smithsonian and was extremely wellconnected he']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the original seed string to see what came after it\n",
    "original_paragraph = corpus[corpus.find(seed_string): corpus.find(seed_string) + 2000]\n",
    "\n",
    "textwrap.wrap(original_paragraph, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51666,
     "status": "ok",
     "timestamp": 1613538454749,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "MSWX94UK8WhN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51661,
     "status": "ok",
     "timestamp": 1613538454749,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "0MKrmY6C8VFL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51657,
     "status": "ok",
     "timestamp": 1613538454750,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "HNC6Lxt__9N-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51652,
     "status": "ok",
     "timestamp": 1613538454750,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "SiYaK6B_AHZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNa5+T0gWfZd3GC6w1ulZ0Z",
   "collapsed_sections": [],
   "name": "Ted Talk Load Model and Predict",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
