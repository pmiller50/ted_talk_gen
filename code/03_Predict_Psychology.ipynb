{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8VMnuH-l2o_"
   },
   "source": [
    "TED talk text generator\n",
    "\n",
    "Generate using a character based model.\n",
    "\n",
    "The code is this notebook is a partial modification of several tutorials, blog posts and YouTube videos. The main sources include:\n",
    "* [Text Generation With LSTM Recurrent Neural Networks in Python with Keras](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/) by Dr. Jason Brownlee\n",
    "* [Text Generation with Python and TensorFlow/Keras](https://stackabuse.com/text-generation-with-python-and-tensorflow-keras/) by Dan Nelson\n",
    "* YouTube: [167 - Text prediction using LSTM (English text)](https://youtu.be/zyCpntcVKSo?t=2) by Sreenivas B.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1613538403438,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "OLpQP9ZPs3Z8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.train import latest_checkpoint\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "import random\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1613538403660,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "waLxIXEXmCoW",
    "outputId": "c9837e2d-5c4e-489f-9030-e6c18a9bcd1a"
   },
   "outputs": [],
   "source": [
    "# Attach to my Google drive so I can save the csv file later\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1613538403660,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "1ygYMqkOddlx"
   },
   "outputs": [],
   "source": [
    "#tag_name = 'all_transcripts'\n",
    "#tag_name = 'brain'\n",
    "#tag_name = 'business'\n",
    "#tag_name = 'creativity'\n",
    "#tag_name = 'culture'\n",
    "tag_name = 'psychology'\n",
    "#tag_name = 'science'\n",
    "\n",
    "lower_corpus = False\n",
    "\n",
    "if lower_corpus:\n",
    "    corpus_file_name = tag_name + '_lowercase'\n",
    "else:\n",
    "    corpus_file_name = tag_name + '_sentence_case'\n",
    "\n",
    "# This switch makes it easier running locally or in a Google Colab environment\n",
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    root_path = '/content/drive/MyDrive/ted/'\n",
    "else:\n",
    "    root_path = '../data/'\n",
    "    \n",
    "sequence_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 863,
     "status": "ok",
     "timestamp": 1613538403661,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "V1ljkpt0l1kx"
   },
   "outputs": [],
   "source": [
    "with open(f'{root_path}{corpus_file_name}.txt', encoding='utf-8') as f:\n",
    "    corpus = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 1322,
     "status": "ok",
     "timestamp": 1613538404130,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "K8pyPFcnmCD9",
    "outputId": "3813cc1e-6871-4766-9709-f5e11b5f7660"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So I want to start by offering you a free no-tech life hack, and all it requires of you is  that you change your posture for two minutes. But before I give it away, I want to ask you to right now do a little audit of your body and what you're doing with your body. So how many of you are sort of making yourselves smaller? Maybe you're hunching, crossing your legs, maybe wrapping your ankles. Sometimes we hold onto our arms like this. Sometimes we spread out.  I see you. So I want you to pay atten\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDIMVXs-kwz3"
   },
   "source": [
    "The code below is used in almost every article I have seen about LSTM for text generation, but this snippet is adapted from :\n",
    "https://www.kaggle.com/mrisdal/intro-to-lstms-w-keras-gpu-for-text-generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "all_chars = sorted(list(set(corpus)))\n",
    "\n",
    "#remove most punctuation, but leave spaces, exclamation points, and periods\n",
    "list_to_remove = ['\"', '&', '-', ',', \"'\", '/', ';',  'â€”']\n",
    "\n",
    "chars = [character for character in all_chars if character not in list_to_remove]\n",
    "print(chars)\n",
    "# hat tip to this post for the idea of removing one list from another\n",
    "# https://www.geeksforgeeks.org/python-remove-all-values-from-a-list-present-in-other-list/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all unwanted characters from the original corpus\n",
    "corpus_list = [character for character in corpus if character not in list_to_remove]\n",
    "\n",
    "# Re-join all letters back into a single string as the updated corpus\n",
    "corpus = ''.join(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1313,
     "status": "ok",
     "timestamp": 1613538404131,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "KW8k2n7piPca",
    "outputId": "70c7cd09-9650-4e03-8fb5-561532a8aeed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in the corpus: 65\n"
     ]
    }
   ],
   "source": [
    "# If running models with punctuation removed, leave commented out\n",
    "#chars = sorted(list(set(corpus)))\n",
    "\n",
    "print('Number of unique characters in the corpus:', len(chars))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1304,
     "status": "ok",
     "timestamp": 1613538404131,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "vwPryvRueRtT",
    "outputId": "a90beecb-f0fc-48ef-e803-c04afc88d5ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '.': 2, '0': 3, '1': 4, '2': 5, '3': 6, '4': 7, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12, '?': 13, 'A': 14, 'B': 15, 'C': 16, 'D': 17, 'E': 18, 'F': 19, 'G': 20, 'H': 21, 'I': 22, 'J': 23, 'K': 24, 'L': 25, 'M': 26, 'N': 27, 'O': 28, 'P': 29, 'Q': 30, 'R': 31, 'S': 32, 'T': 33, 'U': 34, 'V': 35, 'W': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
     ]
    }
   ],
   "source": [
    "# Show character to index mapping\n",
    "print (char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1294,
     "status": "ok",
     "timestamp": 1613538404132,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "RqMa6shPiQrd",
    "outputId": "6965acf5-10cf-4624-efde-abb4f61eeb4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: '!', 2: '.', 3: '0', 4: '1', 5: '2', 6: '3', 7: '4', 8: '5', 9: '6', 10: '7', 11: '8', 12: '9', 13: '?', 14: 'A', 15: 'B', 16: 'C', 17: 'D', 18: 'E', 19: 'F', 20: 'G', 21: 'H', 22: 'I', 23: 'J', 24: 'K', 25: 'L', 26: 'M', 27: 'N', 28: 'O', 29: 'P', 30: 'Q', 31: 'R', 32: 'S', 33: 'T', 34: 'U', 35: 'V', 36: 'W', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# Show index to character mapping\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1286,
     "status": "ok",
     "timestamp": 1613538404132,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "ns5RcDesiQzZ",
    "outputId": "fc7676a5-4d17-4b11-e18c-929b51c72f50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input corpus contains 81,675 characters.\n"
     ]
    }
   ],
   "source": [
    "print (f'The input corpus contains {len(corpus):,} characters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1278,
     "status": "ok",
     "timestamp": 1613538404132,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "85NHcjWuiQ7D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXgbFM-46jrS"
   },
   "source": [
    "The model will use arbitrary length of characters, e.g. 40, and then predict the next character that will appear (the 41st).\n",
    "\n",
    "I would like to change this sequence length in different models, to see how it might affect the model's performance.\n",
    "\n",
    "Larger might be better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1613538404133,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "CgLONw9RiRC-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNWrhS2LJkOt"
   },
   "source": [
    "Loop through the corpus, creating segments of 40 characters, plus a segment of a single character that would appear after it. These segments are then converted into their respective digits, and loaded into X\n",
    "\n",
    "In addition, create a list of target values. The target, y, is a single text character, and is also converted into a corresponding numeric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1265,
     "status": "ok",
     "timestamp": 1613538404133,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "uPWsaG39Si52",
    "outputId": "ec027126-9d6e-4bb4-cd0d-965a7c65f1ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So I want to start by offering you a free notech l'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1613538404133,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "pB06ivEKOa2f",
    "outputId": "7f8f681f-b956-4c94-a8d1-fed28e011bd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o I want to start by offering you a free'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1248,
     "status": "ok",
     "timestamp": 1613538404134,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "QN8H5lmRPzV8",
    "outputId": "ebd703f3-9fd8-4a71-f00a-791ff00b8ceb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 2091,
     "status": "ok",
     "timestamp": 1613538404984,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "z4bwf70jiRIF"
   },
   "outputs": [],
   "source": [
    "# For future modeling, we could try to offset the sequences by more than one\n",
    "# letter. For now the model will look at every sequence right after another.\n",
    "step = 1\n",
    "\n",
    "X_numeric_list = []\n",
    "y_numeric_list = []\n",
    "\n",
    "\n",
    "for i in range (0, len(corpus) - sequence_length, step):\n",
    "    # To find X when still as characters, loop through and extract\n",
    "    # a sequence for example, from the 2nd to the 42nd, as in corpus[1:41] since \n",
    "    # the string index is zero-based\n",
    "    X_char_sequence = corpus[i:i + sequence_length]  #exclusive\n",
    "    y_char = corpus[i + sequence_length]\n",
    "\n",
    "    # Convert the X character sequence into a list of integers, using the \n",
    "    # dictionary created above.\n",
    "    X_numeric_list.append( [char_indices[letter] for letter in X_char_sequence])\n",
    "    # Also convert target letter y to it's corresponding numeric value in the\n",
    "    # dictionary\n",
    "    y_numeric_list.append(char_indices[y_char])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2085,
     "status": "ok",
     "timestamp": 1613538404984,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "OAIoz7XIXIWV",
    "outputId": "1368effc-745f-4a2a-df82-09c0a57e1d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 53, 0, 22, 0, 61, 39, 52, 58, 0, 58, 53, 0, 57, 58, 39, 56, 58, 0, 40, 63, 0, 53, 44, 44, 43, 56, 47, 52, 45, 0, 63, 53, 59, 0, 39, 0, 44, 56, 43]\n",
      "[53, 0, 22, 0, 61, 39, 52, 58, 0, 58, 53, 0, 57, 58, 39, 56, 58, 0, 40, 63, 0, 53, 44, 44, 43, 56, 47, 52, 45, 0, 63, 53, 59, 0, 39, 0, 44, 56, 43, 43]\n"
     ]
    }
   ],
   "source": [
    "# Look at the first two converted sequences\n",
    "print ( X_numeric_list[0])\n",
    "print ( X_numeric_list[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2078,
     "status": "ok",
     "timestamp": 1613538404985,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "W_WYfvRUXLd8",
    "outputId": "41af6ff4-894e-4a89-b1e1-2439439852cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43, 0]\n"
     ]
    }
   ],
   "source": [
    "print ( y_numeric_list[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2071,
     "status": "ok",
     "timestamp": 1613538404985,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "pUBI2jozXYT1",
    "outputId": "5b950e77-26a9-45a7-d5df-a218ee01509e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2064,
     "status": "ok",
     "timestamp": 1613538404986,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "PhR81VtiXzyJ",
    "outputId": "ce15680c-aa72-4aee-9e48-230cfa3acddc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So I want to start by offering you a free n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:43]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2X_QDPSqYAmR"
   },
   "source": [
    "This example is a little hard to follow, since we happened to be in the middle of the word 'been'. The letter e is mapped to 51.\n",
    "\n",
    "However the beginning of the sequence has been shifted by one as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2054,
     "status": "ok",
     "timestamp": 1613538404986,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "nkX8BKMMX4hh",
    "outputId": "7ff2f80c-cfd3-432f-b2ac-fbbf18042b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 81,635 entries in X_numeric_list\n"
     ]
    }
   ],
   "source": [
    "print (f'There are {len(X_numeric_list):,} entries in X_numeric_list') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tn3uKqnJasUf"
   },
   "source": [
    "An LSTM model needs the X data to be in 3 dimensions:\n",
    "* Samples (number of rows)\n",
    "* Time steps (this implies time series. In this example this corresponds to the sequence_length)\n",
    "* Features (the target, or y variable)\n",
    "\n",
    "This [blog post by Dr. John Brownlee](https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/) contains a longer explanation, which I paraphrased here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 2825,
     "status": "ok",
     "timestamp": 1613538405763,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "qH7OG0kAYALM"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "# Samples is the total number of 40 character text fragments created above\n",
    "# Time step is the sequence length, which is this case is 40, but might change\n",
    "# in other model variations\n",
    "# Feature is one, since the model is predicting one character at a time\n",
    "X = np.reshape(X_numeric_list, (len(X_numeric_list), sequence_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2819,
     "status": "ok",
     "timestamp": 1613538405763,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "WYTRXPhbarU0",
    "outputId": "3263bee5-a669-47b5-b02a-9f03e452b4cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81635, 40, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 2813,
     "status": "ok",
     "timestamp": 1613538405764,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "lrG9AduNY47g"
   },
   "outputs": [],
   "source": [
    "# normalize/scale the data by dividing by the length of the character list.\n",
    "X = X / len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2807,
     "status": "ok",
     "timestamp": 1613538405764,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "bhvp9pN5_txN",
    "outputId": "52fbf777-410c-4631-9f36-b7cf535fd51e"
   },
   "outputs": [],
   "source": [
    "# Look at the first value of X\n",
    "#X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cqa6ZNx4AQwE"
   },
   "source": [
    "Even thought the values for the target variable are integers, they are essentially labels for the predicted characters. They are one-hot encoded using the to_categorical function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2794,
     "status": "ok",
     "timestamp": 1613538405765,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "XqS9wPlW_t5F",
    "outputId": "79c00f03-9da9-4588-a73b-a36dad43f0b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y_numeric_list)\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lb1V-QYZFdoe"
   },
   "source": [
    "---\n",
    "### Load LSTM Model\n",
    "In this notebook, load a model that was previously trained and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 2785,
     "status": "ok",
     "timestamp": 1613538405765,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "R1tBdmEw_t-b"
   },
   "outputs": [],
   "source": [
    "# Save the model to my Google Drive so I can load it later from another notebook\n",
    "# model = load_model(f'/content/drive/MyDrive/ted/models/ted_model_{tag_name}')\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tTuw8KwXoh7"
   },
   "source": [
    "If a model failed during fitting, we can still load it's most recent weights which were stored in a checkpoint file.\n",
    "\n",
    "Use of ModelCheckPoint to save the model's progress example as described in the [TensorFlow documentation.](https://www.tensorflow.org/tutorials/keras/save_and_load#checkpoint_callback_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2773,
     "status": "ok",
     "timestamp": 1613538405765,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "fRahDlmOW9gK",
    "outputId": "aab19b18-9798-4c99-a3c8-71998b376e3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/psychology_sentence_case/psychology_sentence_case.ckpt'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "checkpoint_dir = f'{root_path}{corpus_file_name}/'\n",
    "\n",
    "latest = latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6235,
     "status": "ok",
     "timestamp": 1613538409235,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "3TuIcmh9W_16",
    "outputId": "fc764c9f-8eec-4e66-f5c5-9d9c9532645f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 40, 400)           643200    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 40, 400)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 128)               270848    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 65)                8385      \n",
      "=================================================================\n",
      "Total params: 922,433\n",
      "Trainable params: 922,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # define the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(1000, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(256))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "\n",
    "# # Load the previously saved weights\n",
    "# model.load_weights(latest)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam' , metrics = ['accuracy','Recall','Precision'])\n",
    "\n",
    "\n",
    "# #model = load_model(f'{latest}')\n",
    "\n",
    "model = load_model(f'{root_path}models/ted_model_{tag_name}')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yg18vLEitH-5"
   },
   "source": [
    "X_numeric_list contains all of our 40 character sequences. Choose one for a seed for the text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6228,
     "status": "ok",
     "timestamp": 1613538409236,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "3zTBAJRh_uC3",
    "outputId": "d6a0b853-b399-4b7c-e898-0166e55fb84f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random start index for seed text: 1517 sequence.\n",
      "[53, 42, 63, 0, 50, 39, 52, 45, 59, 39, 45, 43, 0, 41, 53, 51, 51, 59, 52, 47, 41, 39, 58, 47, 52, 45, 0, 58, 53, 0, 51, 43, 13, 0, 36, 46, 39, 58, 57, 0]\n"
     ]
    }
   ],
   "source": [
    "seed_start = random.randint(0, len(corpus) - sequence_length)\n",
    "print(f'Random start index for seed text: {seed_start} sequence.')\n",
    "\n",
    "X_seeded = X_numeric_list[seed_start]\n",
    "print(X_seeded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vj_Nlck8FRl"
   },
   "source": [
    "Convert this back to text so we can see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6220,
     "status": "ok",
     "timestamp": 1613538409236,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "lnHGnP3O_uFB",
    "outputId": "e087a11d-97d8-4e5b-efb3-bd0038c269a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ody language communicating to me? Whats '"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_string = ''.join([indices_char[letter_code] for letter_code in X_seeded])\n",
    "seed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6212,
     "status": "ok",
     "timestamp": 1613538409237,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "nmSHu7KtBULP",
    "outputId": "858e7171-be72-46b9-94a1-3d06586e19d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ody language communicating to me? Whats \n",
      "dy language communicating to me? Whats m\n",
      "y language communicating to me? Whats mi\n",
      " language communicating to me? Whats min\n",
      "language communicating to me? Whats mine\n",
      "anguage communicating to me? Whats mine \n",
      "nguage communicating to me? Whats mine c\n",
      "guage communicating to me? Whats mine co\n",
      "uage communicating to me? Whats mine com\n",
      "age communicating to me? Whats mine comm\n",
      "ge communicating to me? Whats mine commu\n",
      "e communicating to me? Whats mine commun\n",
      " communicating to me? Whats mine communi\n",
      "communicating to me? Whats mine communic\n",
      "ommunicating to me? Whats mine communica\n"
     ]
    }
   ],
   "source": [
    "# We can also use the seed_start value to see a larger picture of the original text\n",
    "for j in range(seed_start, seed_start + 15):\n",
    "    seed_numeric = X_numeric_list[j]\n",
    "    print (''.join([indices_char[letter_code] for letter_code in seed_numeric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6205,
     "status": "ok",
     "timestamp": 1613538409237,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "XP-zzHQIBUIa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvDwmnKi8KFC"
   },
   "source": [
    "To generate text, we need to change the input text into a 3D shape as we did the X input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6984,
     "status": "ok",
     "timestamp": 1613538410022,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "21d8U6qaAADc",
    "outputId": "da487977-5e85-4468-8be6-505eb1038510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A prediction's shape:(1, 65)\n",
      "Prediction:\n",
      "[[2.78809806e-03 4.22526441e-08 1.34004731e-05 4.03564741e-07\n",
      "  3.60255683e-04 8.48298441e-06 2.15185602e-04 1.65061209e-08\n",
      "  2.60885349e-06 1.41059099e-05 3.98016482e-07 1.82979605e-07\n",
      "  6.71813323e-05 9.23226366e-07 5.36681873e-05 2.02538344e-04\n",
      "  1.99578717e-05 8.52636062e-04 6.12997916e-04 2.67797277e-05\n",
      "  1.82141830e-05 2.14508109e-04 3.19654047e-02 4.39010182e-05\n",
      "  1.16947685e-05 2.08103975e-05 2.28580175e-04 6.52783419e-05\n",
      "  2.03329000e-05 5.81788154e-05 3.33226815e-08 5.48093776e-05\n",
      "  6.14478995e-05 6.03014705e-05 4.56137786e-06 3.51769245e-07\n",
      "  1.06481066e-05 2.38711636e-05 1.13712273e-09 2.11722121e-01\n",
      "  8.48094281e-03 4.44139168e-03 2.26547243e-03 3.18173468e-02\n",
      "  4.48880903e-03 3.08582536e-03 1.36429546e-02 1.11214556e-01\n",
      "  2.06961809e-03 1.48811971e-03 7.36126676e-03 2.75735203e-02\n",
      "  2.59804726e-02 1.26010135e-01 7.03335460e-03 1.20797602e-03\n",
      "  3.83334421e-03 2.67301667e-02 2.10821226e-01 1.78095866e-02\n",
      "  4.65846155e-04 3.74667421e-02 9.20784078e-06 7.48469681e-02\n",
      "  3.03110774e-05]]\n"
     ]
    }
   ],
   "source": [
    "temp_x = np.reshape(X_seeded, (1, len(X_seeded) , 1))\n",
    "# normalize/scale the data by dividing by the length of the character list.\n",
    "temp_x = temp_x / len(chars)\n",
    "prediction = model.predict(temp_x, verbose=0)\n",
    "print(f\"A prediction's shape:{prediction.shape}\")\n",
    "print('Prediction:')\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dQEpt5uAJcE"
   },
   "source": [
    "Each prediction produces an result of shape (1, 75), and contains a predicted probability of a character. Use argmax to find the index of the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6977,
     "status": "ok",
     "timestamp": 1613538410022,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "7XoGksJ2AIoZ",
    "outputId": "a4ac631e-f9bb-4017-e96f-ed8a8ff4cf1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ax7a5bKoA3FJ"
   },
   "source": [
    "So the first letter predicted after the seed sequence is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6971,
     "status": "ok",
     "timestamp": 1613538410022,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "ErPPRZ-4AIt5",
    "outputId": "ab74b69d-bdd6-4d7d-fc12-a2ad04a99458"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6964,
     "status": "ok",
     "timestamp": 1613538410023,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "cLexXeVQAIza"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51684,
     "status": "ok",
     "timestamp": 1613538454748,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "BE7FR8en_uG3",
    "outputId": "073fe9fc-8225-4372-ccba-e26dda5ea2ff"
   },
   "outputs": [],
   "source": [
    "# Put all predicted characters in a list, then convert to a string later.\n",
    "complete_predicted_text =[]\n",
    "\n",
    "# Generate 1000 characters\n",
    "for i in range(500):\n",
    "    # reshape to 1 row, sequence length, and 1 for predicting one character as the target\n",
    "    temp_x = np.reshape(X_seeded, (1, len(X_seeded) , 1))\n",
    "    # normalize/scale the data by dividing by the length of the character list.\n",
    "    temp_x = temp_x / len(chars)\n",
    "    prediction = model.predict(temp_x, verbose=0)\n",
    "    complete_predicted_text.append(indices_char[np.argmax(prediction)])\n",
    "\n",
    "    # After predicting, add this character's numeric value on to the randomly\n",
    "    # chose seed string, and use this for another prediction\n",
    "    X_seeded.append(np.argmax(prediction))\n",
    "\n",
    "    # Move the seeded text up one character, so create a new sequence\n",
    "    X_seeded = X_seeded[1:len(X_seeded)]\n",
    "\n",
    "\n",
    "#print (complete_predicted_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "le8p2x7pP35N"
   },
   "source": [
    "The predicted results are a list of characters, so convert into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51677,
     "status": "ok",
     "timestamp": 1613538454748,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "F9xdtOGE_-8p",
    "outputId": "d825a21f-5e66-478e-eb9b-beb7b3bd58ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ody language communicating to me? Whats ->a sialat bor the wirh of the pomet whth the person to tell the person to tork',\n",
       " 'of the person to to the perpon to tork of the posesful fxperience about the courre of stress response and soml bounect',\n",
       " 'Thenes a little bot that and sower phople and workeng to be and that wour body language to to the people who were what',\n",
       " 'they were wrrnd of she stress response and tome people that we are the like wes and we could be hi the seoe that wour',\n",
       " 'heart  And then is what wou co they were walt to be willing to bo']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_string = ''.join(complete_predicted_text)\n",
    "\n",
    "# Wrap to 120 characters just so I can visually compare to the original string.\n",
    "textwrap.wrap(seed_string + '->'+ predicted_string, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51672,
     "status": "ok",
     "timestamp": 1613538454749,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "QsIg_Zg8U487",
    "outputId": "740e0b8c-5879-48d4-b85d-975b3d316626"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ody language communicating to me? Whats mine communicating to you? And theres a lot of reason to believe that this is a',\n",
       " 'valid way to look at this. So social scientists have spent a lot of time looking at the effects of our body language or',\n",
       " 'other peoples body language on judgments. And we make sweeping judgments and inferences from body language. And those',\n",
       " 'judgments can predict really meaningful life outcomes like who we hire or promote who we ask out on a date. For example',\n",
       " 'Nalini Ambady a researcher at Tufts University shows that when people watch 30second soundless clips of real',\n",
       " 'physicianpatient interactions their judgments of the physicians niceness predict whether or not that physician will be',\n",
       " 'sued. So it doesnt have to do so much with whether or not that physician was incompetent but do we like that person and',\n",
       " 'how they interacted? Even more dramatic Alex Todorov at Princeton has shown us that judgments of political candidates',\n",
       " 'faces in just one second predict 70 percent of U.S. Senate and gubernatorial race outcomes and even lets go digital',\n",
       " 'emoticons used well in online negotiations can lead you to claim more value from that negotiation. If you use them',\n",
       " 'poorly bad idea. Right? So when we think of nonverbals we think of how we judge others how they judge us and what the',\n",
       " 'outcomes are. We tend to forget though the other audience thats influenced by our nonverbals and thats ourselves. We are',\n",
       " 'also influenced by our nonverbals our thoughts and our feelings and our physiology. So what nonverbals am I talking',\n",
       " 'about? Im a social psychologist. I study prejudice and I teach at a competitive business school so it was inevitable',\n",
       " 'that I would become interested in power dynamics. I became especially interested in nonverbal expressions of power and',\n",
       " 'dominance. And what are nonverbal expressions of power and dominance? Well this is what they are. So in the animal',\n",
       " 'kingdom they are about expanding. So you make yourself big you stretch out you take up space youre basically opening up']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the original seed string to see what came after it\n",
    "original_paragraph = corpus[corpus.find(seed_string): corpus.find(seed_string) + 2000]\n",
    "\n",
    "textwrap.wrap(original_paragraph, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51666,
     "status": "ok",
     "timestamp": 1613538454749,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "MSWX94UK8WhN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51661,
     "status": "ok",
     "timestamp": 1613538454749,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "0MKrmY6C8VFL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51657,
     "status": "ok",
     "timestamp": 1613538454750,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "HNC6Lxt__9N-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51652,
     "status": "ok",
     "timestamp": 1613538454750,
     "user": {
      "displayName": "Paul Miller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXlCJlUNP_Zej2q_vHMWxjMVx5K1clFfHQwY39aUQ=s64",
      "userId": "17552999692727969229"
     },
     "user_tz": 480
    },
    "id": "SiYaK6B_AHZ_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNa5+T0gWfZd3GC6w1ulZ0Z",
   "collapsed_sections": [],
   "name": "Ted Talk Load Model and Predict",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
